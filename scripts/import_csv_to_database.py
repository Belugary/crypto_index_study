#!/usr/bin/env python3
"""
CSV æ•°æ®å¯¼å…¥æ•°æ®åº“è„šæœ¬

ä» data/daily/daily_files/ ä¸­çš„ CSV æ–‡ä»¶æ‰¹é‡å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“ä¸­
"""

import sqlite3
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime
from tqdm import tqdm
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.database_utils import DatabaseManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def import_csv_to_database():
    """ä»CSVæ–‡ä»¶å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“"""
    
    # åˆå§‹åŒ–è·¯å¾„
    daily_files_path = project_root / 'data' / 'daily' / 'daily_files'
    db_path = project_root / 'data' / 'market.db'
    
    print(f"ğŸ“ CSVæ–‡ä»¶è·¯å¾„: {daily_files_path}")
    print(f"ğŸ—ƒï¸  æ•°æ®åº“è·¯å¾„: {db_path}")
    
    if not daily_files_path.exists():
        print("âŒ CSVæ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
        return
        
    if not db_path.exists():
        print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # æ”¶é›†æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = []
    for year_dir in sorted(daily_files_path.glob('20*')):
        if year_dir.is_dir():
            for month_dir in sorted(year_dir.glob('*')):
                if month_dir.is_dir():
                    for date_file in sorted(month_dir.glob('*.csv')):
                        date_str = date_file.stem
                        if len(date_str) == 10 and date_str.count('-') == 2:
                            csv_files.append((date_str, date_file))
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    if len(csv_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶èŒƒå›´
    csv_files.sort()
    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {csv_files[0][0]} åˆ° {csv_files[-1][0]}")
    
    # è¿æ¥æ•°æ®åº“å¹¶å¼€å§‹å¯¼å…¥
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_inserted = 0
            failed_files = []
            
            # å¯¼å…¥æ•°æ®
            for date_str, csv_file in tqdm(csv_files, desc="å¯¼å…¥CSVæ–‡ä»¶"):
                try:
                    # è¯»å–CSVæ–‡ä»¶
                    df = pd.read_csv(csv_file)
                    
                    if df.empty:
                        logger.warning(f"è·³è¿‡ç©ºæ–‡ä»¶: {date_str}")
                        continue
                    
                    # å‡†å¤‡æ•°æ®åº“è®°å½•
                    records = []
                    for _, row in df.iterrows():
                        # é¦–å…ˆç¡®ä¿å¸ç§å­˜åœ¨äº coins è¡¨ä¸­
                        coin_id = row.get('coin_id', '')
                        if not coin_id:
                            continue
                            
                        # æ’å…¥å¸ç§ä¿¡æ¯ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                        cursor.execute("""
                            INSERT OR IGNORE INTO coins (id, symbol, name, last_updated)
                            VALUES (?, ?, ?, ?)
                        """, (
                            coin_id,
                            row.get('symbol', '').upper(),
                            row.get('name', ''),
                            datetime.now().isoformat()
                        ))
                        
                        # å‡†å¤‡æ—¥å¸‚åœºæ•°æ® - æ³¨æ„ä½¿ç”¨ rank è€Œä¸æ˜¯ market_cap_rank
                        timestamp = row.get('timestamp', 0)
                        if pd.isna(timestamp):
                            timestamp = int(datetime.strptime(date_str, '%Y-%m-%d').timestamp() * 1000)
                        
                        record = (
                            coin_id,                        # coin_id
                            date_str,                       # date
                            int(timestamp),                 # timestamp
                            float(row.get('price', 0)) if pd.notna(row.get('price', 0)) else 0,
                            float(row.get('volume', 0)) if pd.notna(row.get('volume', 0)) else 0,
                            float(row.get('market_cap', 0)) if pd.notna(row.get('market_cap', 0)) else 0,
                            int(row.get('rank', 0)) if pd.notna(row.get('rank', 0)) else 0,
                            datetime.now().isoformat()      # created_at
                        )
                        records.append(record)
                    
                    # æ‰¹é‡æ’å…¥æ—¥å¸‚åœºæ•°æ®
                    if records:
                        cursor.executemany("""
                            REPLACE INTO daily_market_data 
                            (coin_id, date, timestamp, price, volume, market_cap, rank, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        """, records)
                        
                        total_inserted += len(records)
                    
                except Exception as e:
                    logger.error(f"å¯¼å…¥æ–‡ä»¶ {date_str} å¤±è´¥: {e}")
                    failed_files.append((date_str, str(e)))
                    continue
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            
            print(f"\nâœ… å¯¼å…¥å®Œæˆ!")
            print(f"ğŸ“Š æ€»è®¡æ’å…¥è®°å½•: {total_inserted:,}")
            
            if failed_files:
                print(f"âŒ å¤±è´¥çš„æ–‡ä»¶: {len(failed_files)}")
                for date_str, error in failed_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"   {date_str}: {error}")
                    
            # éªŒè¯å¯¼å…¥ç»“æœ
            cursor.execute("SELECT COUNT(*) FROM daily_market_data")
            db_records = cursor.fetchone()[0]
            print(f"ğŸ—ƒï¸  æ•°æ®åº“ä¸­æ€»è®°å½•æ•°: {db_records:,}")
            
            cursor.execute("SELECT COUNT(DISTINCT date) FROM daily_market_data")
            db_dates = cursor.fetchone()[0]
            print(f"ğŸ“… æ•°æ®åº“ä¸­æ—¥æœŸæ•°: {db_dates}")
            
            cursor.execute("SELECT MIN(date), MAX(date) FROM daily_market_data")
            date_range = cursor.fetchone()
            print(f"ğŸ“… æ•°æ®åº“æ—¥æœŸèŒƒå›´: {date_range[0]} åˆ° {date_range[1]}")
            
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ä»CSVæ–‡ä»¶å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“...")
    import_csv_to_database()
    print("ğŸ‰ å¯¼å…¥å®Œæˆ!")
