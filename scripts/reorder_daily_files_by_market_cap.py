#!/usr/bin/env python3
"""
æ¯æ—¥æ±‡æ€»æ–‡ä»¶å¸‚å€¼æ’åºä¸æ’åé‡èµ‹å€¼å·¥å…· - è–„å°è£…ç‰ˆæœ¬

åŸºäº src/downloaders/daily_aggregator.py æ ¸å¿ƒæ¨¡å—çš„è–„å°è£…å®ç°ã€‚

åŠŸèƒ½ï¼š
- éå† data/daily/daily_files/ ç›®å½•ä¸‹æ‰€æœ‰æ¯æ—¥æ±‡æ€» CSV æ–‡ä»¶
- æŒ‰å¸‚å€¼å­—æ®µé™åºæ’åº
- ä¾æ¬¡èµ‹å€¼ rank å­—æ®µï¼ˆ1,2,3...ï¼‰
- æ”¯æŒ dry-run æ¨¡å¼ï¼Œä»…è¾“å‡ºæ’åºç»“æœä¸å†™å…¥æ–‡ä»¶
- æ”¯æŒå¤šçº¿ç¨‹åŠ é€Ÿ
- æ”¯æŒæŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ–‡ä»¶

ç”¨æ³•ï¼š
    python scripts/reorder_daily_files_by_market_cap_slim.py [--dry-run] [--max-workers N]
    python scripts/reorder_daily_files_by_market_cap_slim.py --start-date 2024-01-01 --end-date 2024-01-31
"""

import argparse
import logging
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.downloaders.daily_aggregator import create_daily_aggregator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def main():
    """ä¸»å‡½æ•°ï¼šè–„å°è£…å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="æ¯æ—¥æ±‡æ€»æ–‡ä»¶å¸‚å€¼æ’åºä¸æ’åé‡èµ‹å€¼å·¥å…·")
    parser.add_argument(
        "--dry-run", action="store_true", help="ä»…è¾“å‡ºæ’åºç»“æœï¼Œä¸å†™å…¥æ–‡ä»¶"
    )
    parser.add_argument("--max-workers", type=int, default=8, help="æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument(
        "--start-date",
        type=str,
        help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œä»…åœ¨æŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ—¶ä½¿ç”¨",
    )
    parser.add_argument(
        "--end-date", type=str, help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œä»…åœ¨æŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ—¶ä½¿ç”¨"
    )

    args = parser.parse_args()

    print("ğŸ“Š æ¯æ—¥æ–‡ä»¶å¸‚å€¼é‡æ’åºå·¥å…·")
    print("=" * 50)
    
    if args.dry_run:
        print("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šä»…æ˜¾ç¤ºæ’åºç»“æœï¼Œä¸ä¿®æ”¹æ–‡ä»¶")
    
    if args.start_date and args.end_date:
        print(f"ğŸ“… æŒ‰æ—¥æœŸèŒƒå›´å¤„ç†ï¼š{args.start_date} åˆ° {args.end_date}")
    else:
        print("ğŸ“ å¤„ç†æ‰€æœ‰æ¯æ—¥æ–‡ä»¶")

    try:
        # åˆ›å»ºæ ¸å¿ƒèšåˆå™¨
        aggregator = create_daily_aggregator()

        # æ‰§è¡Œé‡æ’åº
        print(f"\nğŸš€ å¼€å§‹é‡æ’åº (å¹¶å‘æ•°: {args.max_workers})...")
        successful, total = aggregator.reorder_daily_files_by_market_cap(
            dry_run=args.dry_run,
            max_workers=args.max_workers,
            start_date=args.start_date,
            end_date=args.end_date
        )

        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“ˆ é‡æ’åºå®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   - æˆåŠŸå¤„ç†: {successful}")
        print(f"   - å¤„ç†å¤±è´¥: {total - successful}")
        print(f"   - æ€»è®¡æ–‡ä»¶: {total}")

        if successful == total and total > 0:
            print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†æˆåŠŸ!")
        elif successful > 0:
            print(f"âš ï¸  éƒ¨åˆ†æ–‡ä»¶å¤„ç†æˆåŠŸ: {successful}/{total}")
        else:
            print("âŒ æ²¡æœ‰æ–‡ä»¶è¢«æˆåŠŸå¤„ç†")

    except Exception as e:
        logger.error(f"é‡æ’åºæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        print(f"âŒ é‡æ’åºå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
