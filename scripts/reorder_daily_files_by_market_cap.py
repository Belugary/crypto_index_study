"""
æ¯æ—¥æ±‡æ€»æ–‡ä»¶å¸‚å€¼æ’åºä¸æ’åé‡èµ‹å€¼å·¥å…·

åŠŸèƒ½ï¼š
- éå† data/daily/daily_files/ ç›®å½•ä¸‹æ‰€æœ‰æ¯æ—¥æ±‡æ€» CSV æ–‡ä»¶
- æŒ‰å¸‚å€¼å­—æ®µé™åºæ’åº
- ä¾æ¬¡èµ‹å€¼ rank å­—æ®µï¼ˆ1,2,3...ï¼‰
- æ”¯æŒ dry-run æ¨¡å¼ï¼Œä»…è¾“å‡ºæ’åºç»“æœä¸å†™å…¥æ–‡ä»¶
- æ”¯æŒå¤šçº¿ç¨‹åŠ é€Ÿ
- æ”¯æŒæŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ–‡ä»¶

ç”¨æ³•ï¼š
python scripts/reorder_daily_files_by_market_cap.py [--dry-run] [--max-workers N]

"""

import os
import glob
import pandas as pd
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Tuple, Optional
from datetime import datetime, timedelta


def process_file(file_path: str, dry_run: bool = False) -> Tuple[str, bool]:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶çš„æ’åºå’Œæ’åé‡åˆ†é…

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼

    Returns:
        Tuple[str, bool]: (æ–‡ä»¶å, æ˜¯å¦æˆåŠŸ)
    """
    try:
        df = pd.read_csv(file_path)

        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
        if "market_cap" not in df.columns or "rank" not in df.columns:
            return os.path.basename(file_path), False

        # å¸‚å€¼å­—æ®µé™åºæ’åº
        df_sorted = df.sort_values(by="market_cap", ascending=False)
        # é‡æ–°èµ‹å€¼æ’å
        df_sorted["rank"] = range(1, len(df_sorted) + 1)

        if dry_run:
            print(f"[DRY-RUN] {os.path.basename(file_path)} æ’åºåå‰5:")
            print(df_sorted.head())
        else:
            df_sorted.to_csv(file_path, index=False)

        return os.path.basename(file_path), True
    except Exception as e:
        print(f"å¤„ç†å¤±è´¥ {os.path.basename(file_path)}: {e}")
        return os.path.basename(file_path), False


def find_daily_files(daily_dir: str = "data/daily/daily_files") -> List[str]:
    """
    æŸ¥æ‰¾æ‰€æœ‰æ¯æ—¥æ±‡æ€»æ–‡ä»¶

    Args:
        daily_dir: æ¯æ—¥æ–‡ä»¶ç›®å½•

    Returns:
        List[str]: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    files = []
    if not os.path.exists(daily_dir):
        print(f"ç›®å½•ä¸å­˜åœ¨: {daily_dir}")
        return files

    for year_dir in os.listdir(daily_dir):
        year_path = os.path.join(daily_dir, year_dir)
        if os.path.isdir(year_path) and year_dir not in [".backup", ".git"]:
            for month_dir in os.listdir(year_path):
                month_path = os.path.join(year_path, month_dir)
                if os.path.isdir(month_path) and month_dir not in [".backup", ".git"]:
                    csv_files = glob.glob(os.path.join(month_path, "*.csv"))
                    files.extend(csv_files)
    return files


def reorder_all_daily_files(
    dry_run: bool = False,
    max_workers: int = 8,
    target_files: Optional[List[str]] = None,
) -> Tuple[int, int]:
    """
    é‡æ’åºæ‰€æœ‰æ¯æ—¥æ±‡æ€»æ–‡ä»¶

    Args:
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        target_files: æŒ‡å®šçš„ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰æ–‡ä»¶

    Returns:
        Tuple[int, int]: (æˆåŠŸæ•°é‡, æ€»æ•°é‡)
    """
    if target_files is None:
        files = find_daily_files()
    else:
        files = target_files

    print(f"å¾…å¤„ç†æ¯æ—¥æ–‡ä»¶æ•°: {len(files)}")
    if files:
        print(f"ç¤ºä¾‹æ–‡ä»¶: {files[:3]}")

    successful = 0
    failed = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {
            executor.submit(process_file, file_path, dry_run): file_path
            for file_path in files
        }

        # ç­‰å¾…å®Œæˆå¹¶æ”¶é›†ç»“æœ
        for future in as_completed(future_to_file):
            file_name, success = future.result()
            if success:
                successful += 1
                if not dry_run:
                    print(f"å·²é‡æ’åº: {file_name}")
            else:
                failed += 1

    print(f"\nå¤„ç†å®Œæˆ: æˆåŠŸ {successful}, å¤±è´¥ {failed}, æ€»è®¡ {len(files)}")
    return successful, len(files)


def reorder_files_by_date_range(
    start_date: str, end_date: str, dry_run: bool = False, max_workers: int = 8
) -> Tuple[int, int]:
    """
    æŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œåªå¤„ç†æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ–‡ä»¶ï¼‰

    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°

    Returns:
        Tuple[int, int]: (æˆåŠŸæ•°é‡, æ€»æ•°é‡)
    """

    # è§£ææ—¥æœŸ
    try:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d").date()
        end_dt = datetime.strptime(end_date, "%Y-%m-%d").date()
    except ValueError as e:
        print(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
        return 0, 0

    # æŸ¥æ‰¾æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ–‡ä»¶
    daily_dir = "data/daily/daily_files"
    target_files = []

    current_date = start_dt
    while current_date <= end_dt:
        year_month_dir = f"{daily_dir}/{current_date.year:04d}/{current_date.month:02d}"
        file_name = f"{current_date.strftime('%Y-%m-%d')}.csv"
        file_path = f"{year_month_dir}/{file_name}"

        if os.path.exists(file_path):
            target_files.append(file_path)

        # ä¸‹ä¸€å¤©
        current_date += timedelta(days=1)

    if not target_files:
        print(f"ğŸ“ æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°æ–‡ä»¶: {start_date} åˆ° {end_date}")
        return 0, 0

    print(f"ğŸ¯ é’ˆå¯¹æ€§é‡æ’åº: {start_date} åˆ° {end_date} ({len(target_files)} ä¸ªæ–‡ä»¶)")

    return reorder_all_daily_files(
        dry_run=dry_run, max_workers=max_workers, target_files=target_files
    )


def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¯æ—¥æ±‡æ€»æ–‡ä»¶å¸‚å€¼æ’åºä¸æ’åé‡èµ‹å€¼å·¥å…·")
    parser.add_argument(
        "--dry-run", action="store_true", help="ä»…è¾“å‡ºæ’åºç»“æœï¼Œä¸å†™å…¥æ–‡ä»¶"
    )
    parser.add_argument("--max-workers", type=int, default=8, help="æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument(
        "--start-date",
        type=str,
        help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œä»…åœ¨æŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ—¶ä½¿ç”¨",
    )
    parser.add_argument(
        "--end-date", type=str, help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œä»…åœ¨æŒ‰æ—¥æœŸèŒƒå›´é‡æ’åºæ—¶ä½¿ç”¨"
    )
    args = parser.parse_args()

    if args.start_date and args.end_date:
        successful, total = reorder_files_by_date_range(
            start_date=args.start_date,
            end_date=args.end_date,
            dry_run=args.dry_run,
            max_workers=args.max_workers,
        )
    else:
        successful, total = reorder_all_daily_files(
            dry_run=args.dry_run, max_workers=args.max_workers
        )

    if successful == total and total > 0:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†æˆåŠŸ!")
    elif successful > 0:
        print(f"âš ï¸  éƒ¨åˆ†æ–‡ä»¶å¤„ç†æˆåŠŸ: {successful}/{total}")
    else:
        print("âŒ æ²¡æœ‰æ–‡ä»¶è¢«æˆåŠŸå¤„ç†")


if __name__ == "__main__":
    main()
