#!/usr/bin/env python3
"""
æ™ºèƒ½æ›´æ–°æ‰€æœ‰ç°æœ‰å¸ç§æ•°æ®

è¯¥è„šæœ¬ä½¿ç”¨æ›´æ–°æ—¥å¿—æ¥é«˜æ•ˆåœ°æ›´æ–° `data/coins` ç›®å½•ä¸­çš„æ‰€æœ‰å¸ç§æ•°æ®æ–‡ä»¶ã€‚
å®ƒä¼šè·³è¿‡ä»Šå¤©å·²ç»æ›´æ–°è¿‡çš„å¸ç§ï¼Œå¹¶ä¸ºæ•´ä¸ªè¿‡ç¨‹æä¾›è¿›åº¦æ¡ã€‚

ä½¿ç”¨æ–¹å¼:
    python scripts/update_all_existing_coins.py
"""

import argparse
import logging
import os
import sys
from datetime import date, datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.updaters.price_updater import PriceDataUpdater

# --- é…ç½® ---
LOG_FILE = "logs/update_all_existing_coins.log"
COINS_DIR = Path("data/coins")
METADATA_DIR = Path("data/metadata")
UPDATE_LOG_PATH = METADATA_DIR / "update_log.csv"

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class UpdateLogger:
    """
    ç®¡ç†æ›´æ–°æ—¥å¿— (update_log.csv)
    """

    def __init__(self, log_path: Path):
        self.log_path = log_path
        self.log_df = self._load_or_create_log()

    def _load_or_create_log(self) -> pd.DataFrame:
        """åŠ è½½æˆ–åˆ›å»ºæ›´æ–°æ—¥å¿—"""
        self.log_path.parent.mkdir(parents=True, exist_ok=True)
        if self.log_path.exists():
            logger.info(f"ä» {self.log_path} åŠ è½½æ›´æ–°æ—¥å¿—")
            return pd.read_csv(self.log_path)
        else:
            logger.info(f"åˆ›å»ºæ–°çš„æ›´æ–°æ—¥å¿—: {self.log_path}")
            df = pd.DataFrame(columns=["coin_id", "last_updated"])
            df.to_csv(self.log_path, index=False)
            return df

    def get_last_update_date(self, coin_id: str) -> Optional[date]:
        """è·å–å¸ç§çš„æœ€åæ›´æ–°æ—¥æœŸ"""
        record = self.log_df[self.log_df["coin_id"] == coin_id]
        if not record.empty:
            try:
                return datetime.strptime(
                    record.iloc[0]["last_updated"], "%Y-%m-%d"
                ).date()
            except (ValueError, TypeError):
                return None
        return None

    def log_update(self, coin_id: str):
        """è®°å½•å¸ç§çš„æ›´æ–°æ—¶é—´"""
        today_str = date.today().strftime("%Y-%m-%d")
        if coin_id in self.log_df["coin_id"].values:
            self.log_df.loc[self.log_df["coin_id"] == coin_id, "last_updated"] = (
                today_str
            )
        else:
            new_record = pd.DataFrame([{"coin_id": coin_id, "last_updated": today_str}])
            self.log_df = pd.concat([self.log_df, new_record], ignore_index=True)

    def save_log(self):
        """ä¿å­˜æ›´æ–°æ—¥å¿—"""
        self.log_df.to_csv(self.log_path, index=False)
        logger.info(f"æ›´æ–°æ—¥å¿—å·²ä¿å­˜åˆ° {self.log_path}")


def get_coins_to_update(
    all_coins: List[str], update_logger: UpdateLogger
) -> Tuple[List[str], List[str]]:
    """
    æ ¹æ®æ›´æ–°æ—¥å¿—ç­›é€‰éœ€è¦æ›´æ–°çš„å¸ç§
    """
    today = date.today()
    needs_update = []
    already_updated = []

    for coin_id in tqdm(all_coins, desc="æ£€æŸ¥æ›´æ–°çŠ¶æ€"):
        last_update = update_logger.get_last_update_date(coin_id)
        if last_update != today:
            needs_update.append(coin_id)
        else:
            already_updated.append(coin_id)

    return needs_update, already_updated


def run_update(
    updater: PriceDataUpdater,
    coins_to_update: List[str],
    update_logger: UpdateLogger,
    max_workers: int,
) -> Tuple[int, int]:
    """
    ä½¿ç”¨å¹¶è¡Œå¤„ç†æ›´æ–°æ‰€æœ‰éœ€è¦æ›´æ–°çš„å¸ç§
    """
    success_count = 0
    fail_count = 0

    with tqdm(total=len(coins_to_update), desc="æ›´æ–°å¸ç§æ•°æ®") as pbar:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_coin = {
                executor.submit(updater.download_coin_data, coin_id): coin_id
                for coin_id in coins_to_update
            }

            for future in as_completed(future_to_coin):
                coin_id = future_to_coin[future]
                try:
                    success, _ = future.result()
                    if success:
                        success_count += 1
                        update_logger.log_update(coin_id)
                    else:
                        fail_count += 1
                except Exception as e:
                    logger.error(f"æ›´æ–° {coin_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    fail_count += 1
                pbar.update(1)

    return success_count, fail_count


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ›´æ–°æ‰€æœ‰ç°æœ‰å¸ç§æ•°æ®")
    parser.add_argument(
        "--max-workers",
        type=int,
        default=10,
        help="å¹¶è¡Œä¸‹è½½çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 10)",
    )
    parser.add_argument(
        "--force-all",
        action="store_true",
        help="å¼ºåˆ¶æ›´æ–°æ‰€æœ‰å¸ç§ï¼Œå¿½ç•¥æ›´æ–°æ—¥å¿—",
    )
    args = parser.parse_args()

    print("ğŸ”„ æ™ºèƒ½æ›´æ–°æ‰€æœ‰ç°æœ‰å¸ç§å·¥å…·")
    print("=" * 50)

    if not COINS_DIR.exists():
        logger.error(f"âŒ å¸ç§æ•°æ®ç›®å½•ä¸å­˜åœ¨: {COINS_DIR}")
        sys.exit(1)

    try:
        # 1. åˆå§‹åŒ–
        all_coin_ids = sorted([f.stem for f in COINS_DIR.glob("*.csv")])
        update_logger = UpdateLogger(UPDATE_LOG_PATH)
        updater = PriceDataUpdater()

        print(f"å‘ç° {len(all_coin_ids)} ä¸ªç°æœ‰å¸ç§")

        # 2. ç­›é€‰éœ€è¦æ›´æ–°çš„å¸ç§
        if args.force_all:
            print("âš¡ï¸ å¼ºåˆ¶æ¨¡å¼ï¼šå°†æ›´æ–°æ‰€æœ‰å¸ç§")
            needs_update = all_coin_ids
            already_updated = []
        else:
            needs_update, already_updated = get_coins_to_update(
                all_coin_ids, update_logger
            )

        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»å¸ç§æ•°: {len(all_coin_ids)}")
        print(f"   - ä»Šæ—¥å·²æ›´æ–° (è·³è¿‡): {len(already_updated)}")
        print(f"   - éœ€è¦æ›´æ–°: {len(needs_update)}")

        if not needs_update:
            print("\nâœ… æ‰€æœ‰å¸ç§éƒ½æ˜¯ä»Šæ—¥æœ€æ–°æ•°æ®ï¼Œæ— éœ€æ›´æ–°ï¼")
            return

        # 3. æ‰§è¡Œæ›´æ–°
        print(
            f"\nğŸš€ å¼€å§‹æ›´æ–° {len(needs_update)} ä¸ªå¸ç§ (å¹¶è¡Œæ•°: {args.max_workers})..."
        )
        success_count, fail_count = run_update(
            updater, needs_update, update_logger, args.max_workers
        )

        # 4. ä¿å­˜æ—¥å¿—å¹¶æŠ¥å‘Šç»“æœ
        update_logger.save_log()

        print(f"\nğŸ¯ æ›´æ–°å®Œæˆï¼")
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   - æˆåŠŸæ›´æ–°: {success_count}")
        print(f"   - æ›´æ–°å¤±è´¥: {fail_count}")

        if fail_count > 0:
            print(f"\nâš ï¸  æœ‰ {fail_count} ä¸ªå¸ç§æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: {LOG_FILE}")
        else:
            print(f"\nâœ… æ‰€æœ‰éœ€è¦æ›´æ–°çš„å¸ç§éƒ½å·²æˆåŠŸå¤„ç†ï¼")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        # ç¡®ä¿åœ¨ä¸­æ–­æ—¶ä¹Ÿèƒ½ä¿å­˜å·²å®Œæˆçš„æ—¥å¿—
        if "update_logger" in locals():
            update_logger.save_log()
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        if "update_logger" in locals():
            update_logger.save_log()
        sys.exit(1)


if __name__ == "__main__":
    main()
