"""
æ‰¹é‡æ›´æ–°åŠ å¯†è´§å¸é‡ä»·æ•°æ®

è¯¥è„šæœ¬ä¼šï¼š
1. è·å–å¸‚å€¼å‰Nåçš„åŠ å¯†è´§å¸
2. ä¸ç°æœ‰coinsç›®å½•å¯¹æ¯”ï¼Œå‘ç°æ–°å¸ç§
3. æ£€æµ‹æ¯ä¸ªå¸ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ
4. å¢é‡ä¸‹è½½ç¼ºå¤±çš„é‡ä»·æ•°æ®
5. æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ®
6. ç”Ÿæˆæ›´æ–°æŠ¥å‘Šå¹¶æ›´æ–°README
"""

import os
import sys
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
import pandas as pd
from pandas.errors import OutOfBoundsDatetime
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.api.coingecko import CoinGeckoAPI
from src.data.batch_downloader import create_batch_downloader
from examples.stablecoin_checker import StablecoinChecker


# APIé™æµé…ç½® (CoinGecko Analystè®¡åˆ’)
RATE_LIMIT_CONFIG = {
    "calls_per_minute": 500,
    "delay_seconds": 0.13,  # 500/min = 8.33/sec â‰ˆ 0.12sé—´éš”ï¼Œä¿é™©èµ·è§ç”¨0.13s
    "batch_size": 50,  # æ¯æ‰¹å¤„ç†å¸ç§æ•°
    "max_retries": 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
}

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
Path("logs").mkdir(exist_ok=True)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("logs/price_data_update.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class PriceDataUpdater:
    """é‡ä»·æ•°æ®æ›´æ–°å™¨"""

    def __init__(self, api=None, downloader=None, checker=None):
        """
        åˆå§‹åŒ–é‡ä»·æ•°æ®æ›´æ–°å™¨

        Args:
            api: CoinGeckoAPI å®ä¾‹
            downloader: BatchDownloader å®ä¾‹
            checker: StablecoinChecker å®ä¾‹
        """
        self.api = api or CoinGeckoAPI()
        self.downloader = downloader or create_batch_downloader()
        self.checker = checker or StablecoinChecker()
        self.coins_dir = Path("data/coins")
        self.metadata_dir = Path("data/metadata")

        self.errors = []
        self.updated_coins = []
        self.new_coins = []

        self.stats = {
            "total_coins": 0,
            "new_coins": 0,
            "updated_coins": 0,
            "failed_coins": 0,
            "total_api_calls": 0,
            "start_time": None,
            "end_time": None,
        }

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        Path("logs").mkdir(exist_ok=True)

    def get_top_n_coins_by_market_cap(self, n: int = 500) -> List[Dict]:
        """
        è·å–å¸‚å€¼å‰Nåçš„åŠ å¯†è´§å¸

        Args:
            n: è·å–å‰Nå

        Returns:
            å¸ç§åˆ—è¡¨
        """
        logger.info(f"ğŸ” è·å–å¸‚å€¼å‰ {n} ååŠ å¯†è´§å¸")

        all_coins = []
        page = 1
        per_page = 250  # CoinGeckoå•é¡µæœ€å¤§å€¼

        with tqdm(desc="è·å–å¸‚å€¼æ’å", unit="é¡µ", leave=True) as pbar:
            while len(all_coins) < n:
                try:
                    logger.info(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µå¸‚åœºæ•°æ®...")

                    # è®¡ç®—æœ¬é¡µéœ€è¦è·å–çš„æ•°é‡
                    remaining = n - len(all_coins)
                    current_per_page = min(per_page, remaining)

                    coins = self.api.get_coins_markets(
                        vs_currency="usd",
                        order="market_cap_desc",
                        per_page=current_per_page,
                        page=page,
                    )

                    if not coins:
                        logger.warning(f"ç¬¬ {page} é¡µæœªè·å–åˆ°æ•°æ®ï¼Œåœæ­¢è·å–")
                        break

                    all_coins.extend(coins)
                    self.stats["total_api_calls"] += 1

                    pbar.update(1)
                    pbar.set_postfix(
                        {"å·²è·å–": len(all_coins), "ç›®æ ‡": n, "å½“å‰é¡µ": page}
                    )

                    page += 1

                    # APIé™æµå»¶è¿Ÿ
                    time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])

                except Exception as e:
                    error_msg = f"è·å–ç¬¬ {page} é¡µå¸‚åœºæ•°æ®å¤±è´¥: {e}"
                    logger.error(error_msg)
                    self.errors.append(error_msg)
                    break

        # ç¡®ä¿åªè¿”å›å‰Nå
        result = all_coins[:n]
        logger.info(f"âœ… æˆåŠŸè·å– {len(result)} ä¸ªå¸ç§çš„å¸‚å€¼æ’å")

        return result

    def get_existing_coin_ids(self) -> Set[str]:
        """
        è·å–ç°æœ‰coinsç›®å½•ä¸­çš„å¸ç§ID

        Returns:
            å¸ç§IDé›†åˆ
        """
        existing_ids = set()

        if self.coins_dir.exists():
            for csv_file in self.coins_dir.glob("*.csv"):
                coin_id = csv_file.stem
                existing_ids.add(coin_id)

        logger.info(f"ğŸ“‹ ç°æœ‰å¸ç§æ•°é‡: {len(existing_ids)}")
        return existing_ids

    def find_new_coins(
        self, top_coins: List[Dict], existing_ids: Set[str]
    ) -> List[Dict]:
        """
        æ‰¾å‡ºæ–°çš„å¸ç§

        Args:
            top_coins: å¸‚å€¼å‰Nåå¸ç§
            existing_ids: ç°æœ‰å¸ç§IDé›†åˆ

        Returns:
            æ–°å¸ç§åˆ—è¡¨
        """
        new_coins = []

        for coin in top_coins:
            coin_id = coin["id"]
            if coin_id not in existing_ids:
                new_coins.append(coin)

        logger.info(f"ğŸ†• å‘ç°æ–°å¸ç§: {len(new_coins)} ä¸ª")
        for coin in new_coins:
            logger.info(
                f"   - {coin['name']} ({coin['symbol'].upper()}) - å¸‚å€¼æ’å: {coin['market_cap_rank']}"
            )

        return new_coins

    def get_coin_last_date(self, coin_id: str) -> Optional[str]:
        """
        è·å–å¸ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ

        Args:
            coin_id: å¸ç§ID

        Returns:
            æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD) æˆ– None
        """
        csv_file = self.coins_dir / f"{coin_id}.csv"

        if not csv_file.exists():
            logger.debug(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ä¸å­˜åœ¨")
            return None

        try:
            df = pd.read_csv(csv_file)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—ï¼ˆå¯èƒ½æ˜¯timestampæˆ–dateï¼‰
            time_column = None
            if "date" in df.columns:
                time_column = "date"
            elif "timestamp" in df.columns:
                time_column = "timestamp"
            else:
                logger.warning(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ç¼ºå°‘æ—¶é—´åˆ—ï¼ˆdateæˆ–timestampï¼‰")
                return None

            if len(df) == 0:
                logger.warning(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ä¸ºç©º")
                return None

            # è·å–æœ€æ–°æ—¥æœŸ
            if time_column == "timestamp":
                # å¦‚æœæ˜¯timestampï¼Œéœ€è¦æ­£ç¡®å¤„ç†å•ä½
                try:
                    # å°è¯•æ¯«ç§’å•ä½
                    df["date"] = pd.to_datetime(df["timestamp"], unit="ms").dt.strftime(
                        "%Y-%m-%d"
                    )
                    last_date = df["date"].max()
                except (ValueError, OutOfBoundsDatetime):
                    try:
                        # å°è¯•ç§’å•ä½
                        df["date"] = pd.to_datetime(
                            df["timestamp"], unit="s"
                        ).dt.strftime("%Y-%m-%d")
                        last_date = df["date"].max()
                    except (ValueError, OutOfBoundsDatetime):
                        logger.warning(f"ğŸ“„ {coin_id}: æ— æ³•è§£ætimestampæ ¼å¼")
                        return None
            else:
                last_date = df[time_column].max()

            logger.debug(f"ğŸ“„ {coin_id}: æœ€æ–°æ•°æ®æ—¥æœŸ {last_date}")
            return last_date

        except Exception as e:
            logger.warning(f"ğŸ“„ {coin_id}: è¯»å–CSVæ–‡ä»¶å¤±è´¥ - {e}")
            return None

    def needs_update(self, coin_id: str) -> Tuple[bool, Optional[str]]:
        """
        æ£€æŸ¥å¸ç§æ˜¯å¦éœ€è¦æ›´æ–°

        Args:
            coin_id: å¸ç§ID

        Returns:
            (æ˜¯å¦éœ€è¦æ›´æ–°, æœ€æ–°æ—¥æœŸ)
        """
        last_date = self.get_coin_last_date(coin_id)

        if last_date is None:
            return True, None  # æ–°å¸ç§ï¼Œéœ€è¦ä¸‹è½½å…¨éƒ¨æ•°æ®

        try:
            last_datetime = datetime.strptime(last_date, "%Y-%m-%d")
            today = datetime.now()

            # å¦‚æœæœ€æ–°æ•°æ®ä¸æ˜¯ä»Šå¤©ï¼Œåˆ™éœ€è¦æ›´æ–°
            if last_datetime.date() < today.date():
                return True, last_date

        except ValueError:
            logger.warning(f"è§£ææ—¥æœŸå¤±è´¥: {last_date}")
            return True, last_date

        return False, last_date

    def download_coin_data(
        self, coin_id: str, is_new_coin: bool = False, from_date: Optional[str] = None
    ) -> bool:
        """
        ä¸‹è½½å¸ç§çš„é‡ä»·æ•°æ®

        Args:
            coin_id: å¸ç§ID
            is_new_coin: æ˜¯å¦ä¸ºæ–°å¸ç§
            from_date: èµ·å§‹æ—¥æœŸ (å¢é‡æ›´æ–°æ—¶ä½¿ç”¨)

        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            if is_new_coin:
                # æ–°å¸ç§ï¼Œä¸‹è½½æœ€å¤§å¤©æ•°çš„å†å²æ•°æ®
                logger.info(f"ğŸ“¥ ä¸‹è½½æ–°å¸ç§ {coin_id} çš„å®Œæ•´å†å²æ•°æ®...")
                success = self.downloader.download_coin_data(
                    coin_id=coin_id, days="max", vs_currency="usd"
                )
            else:
                # ç°æœ‰å¸ç§ï¼Œå¢é‡æ›´æ–°
                if from_date:
                    # è®¡ç®—éœ€è¦æ›´æ–°çš„å¤©æ•°
                    from_datetime = datetime.strptime(from_date, "%Y-%m-%d")
                    today = datetime.now()
                    days_to_update = (today - from_datetime).days + 1

                    logger.info(
                        f"ğŸ“¥ å¢é‡æ›´æ–° {coin_id}ï¼Œä» {from_date} å¼€å§‹ï¼Œå…± {days_to_update} å¤©..."
                    )
                    success = self.downloader.download_coin_data(
                        coin_id=coin_id, days=str(days_to_update), vs_currency="usd"
                    )
                else:
                    # æ— æ³•ç¡®å®šèµ·å§‹æ—¥æœŸï¼Œé‡æ–°ä¸‹è½½å…¨éƒ¨æ•°æ®
                    logger.info(
                        f"ğŸ“¥ é‡æ–°ä¸‹è½½ {coin_id} çš„å®Œæ•´å†å²æ•°æ®ï¼ˆæ— æ³•ç¡®å®šå¢é‡èµ·å§‹ç‚¹ï¼‰..."
                    )
                    success = self.downloader.download_coin_data(
                        coin_id=coin_id, days="max", vs_currency="usd"
                    )

            if success:
                logger.info(f"âœ… {coin_id} æ•°æ®ä¸‹è½½æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ {coin_id} æ•°æ®ä¸‹è½½å¤±è´¥")
                return False

        except Exception as e:
            error_msg = f"ä¸‹è½½ {coin_id} æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)
            return False

    def update_stablecoin_metadata(self):
        """
        æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ® (å¤ç”¨å·²æœ‰æ•°æ®)
        """
        logger.info("ğŸ’° æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ®...")

        try:
            # è·å–æ‰€æœ‰éœ€è¦å…ƒæ•°æ®çš„å¸ç§
            coin_ids = [f.stem for f in self.coins_dir.glob("*.csv")]

            # æ£€æŸ¥å“ªäº›å¸ç§ç¼ºå°‘å…ƒæ•°æ®
            missing_metadata = []
            for coin_id in coin_ids:
                metadata_file = self.metadata_dir / "coin_metadata" / f"{coin_id}.json"
                if not metadata_file.exists():
                    missing_metadata.append(coin_id)

            if missing_metadata:
                logger.info(
                    f"ğŸ”„ å‘ç° {len(missing_metadata)} ä¸ªå¸ç§ç¼ºå°‘å…ƒæ•°æ®ï¼Œå¼€å§‹æ›´æ–°..."
                )

                # æ‰¹é‡æ›´æ–°ç¼ºå¤±çš„å…ƒæ•°æ®
                results = self.downloader.batch_update_coin_metadata(
                    coin_ids=missing_metadata,
                    force=False,
                    delay_seconds=RATE_LIMIT_CONFIG["delay_seconds"],
                )

                success_count = sum(1 for success in results.values() if success)
                logger.info(
                    f"âœ… å…ƒæ•°æ®æ›´æ–°å®Œæˆ: {success_count}/{len(missing_metadata)} æˆåŠŸ"
                )

                self.stats["total_api_calls"] += len(missing_metadata)
            else:
                logger.info("âœ… æ‰€æœ‰å¸ç§å…ƒæ•°æ®éƒ½æ˜¯æœ€æ–°çš„")

            # é‡æ–°ç”Ÿæˆç¨³å®šå¸åˆ—è¡¨
            checker = StablecoinChecker()
            success = checker.export_stablecoins_csv()

            if success:
                logger.info("âœ… ç¨³å®šå¸åˆ—è¡¨æ›´æ–°æˆåŠŸ")
            else:
                logger.error("âŒ ç¨³å®šå¸åˆ—è¡¨æ›´æ–°å¤±è´¥")

        except Exception as e:
            error_msg = f"æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

    def generate_update_report(self) -> str:
        """
        ç”Ÿæˆæ›´æ–°æŠ¥å‘Š

        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        duration = self.stats["end_time"] - self.stats["start_time"]

        report = f"""
ğŸ” é‡ä»·æ•°æ®æ›´æ–°æŠ¥å‘Š
{'='*60}
ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
   - æ€»å¸ç§æ•°: {self.stats['total_coins']}
   - æ–°å¸ç§æ•°: {self.stats['new_coins']}
   - æ›´æ–°å¸ç§æ•°: {self.stats['updated_coins']}
   - å¤±è´¥å¸ç§æ•°: {self.stats['failed_coins']}
   - APIè°ƒç”¨æ¬¡æ•°: {self.stats['total_api_calls']}
   - æ€»è€—æ—¶: {duration}

ğŸ• æ—¶é—´ä¿¡æ¯:
   - å¼€å§‹æ—¶é—´: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
   - ç»“æŸæ—¶é—´: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}

{'âŒ é”™è¯¯ä¿¡æ¯:' if self.errors else 'âœ… æ— é”™è¯¯'}
"""

        if self.errors:
            for i, error in enumerate(self.errors, 1):
                report += f"   {i}. {error}\n"

        return report

    def update_readme_timestamp(self):
        """
        æ›´æ–°README.mdä¸­çš„æœ€è¿‘æ›´æ–°æ—¶é—´
        """
        readme_path = Path("README.md")

        if not readme_path.exists():
            logger.warning("README.md æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ—¶é—´æˆ³æ›´æ–°")
            return

        try:
            content = readme_path.read_text(encoding="utf-8")
            today = datetime.now().strftime("%Y-%m-%d")

            # æŸ¥æ‰¾å¹¶æ›¿æ¢æ›´æ–°æ—¶é—´
            import re

            pattern = r"\(æœ€è¿‘æ›´æ–°: \d{4}-\d{2}-\d{2}\)"
            replacement = f"(æœ€è¿‘æ›´æ–°: {today})"

            if re.search(pattern, content):
                new_content = re.sub(pattern, replacement, content)
                readme_path.write_text(new_content, encoding="utf-8")
                logger.info(f"âœ… README.md æ›´æ–°æ—¶é—´å·²æ›´æ–°ä¸º: {today}")
            else:
                logger.warning("README.md ä¸­æœªæ‰¾åˆ°æ›´æ–°æ—¶é—´æ ¼å¼ï¼Œè·³è¿‡æ›´æ–°")

        except Exception as e:
            error_msg = f"æ›´æ–°README.mdæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

    def run(self, top_n: int = 500) -> None:
        """
        æ‰§è¡Œå®Œæ•´çš„é‡ä»·æ•°æ®æ›´æ–°æµç¨‹

        Args:
            top_n: å¸‚å€¼å‰Nå
        """
        logger.info(f"ğŸš€ å¼€å§‹é‡ä»·æ•°æ®æ›´æ–°æµç¨‹ (å‰{top_n}å)")
        logger.info("=" * 60)

        self.stats["start_time"] = datetime.now()

        try:
            # 1. è·å–å¸‚å€¼å‰Nåå¸ç§
            top_coins = self.get_top_n_coins_by_market_cap(top_n)
            if not top_coins:
                logger.error("âŒ æ— æ³•è·å–å¸‚å€¼æ’åæ•°æ®")
                return

            # 2. è·å–ç°æœ‰å¸ç§ID
            existing_ids = self.get_existing_coin_ids()

            # 3. æ‰¾å‡ºæ–°å¸ç§
            new_coins = self.find_new_coins(top_coins, existing_ids)
            self.stats["new_coins"] = len(new_coins)

            # 4. åˆå¹¶æ‰€æœ‰éœ€è¦å¤„ç†çš„å¸ç§
            all_target_coins = {coin["id"]: coin for coin in top_coins}

            # æ·»åŠ ç°æœ‰å¸ç§ï¼ˆå¯èƒ½ä¸åœ¨å‰Nåä¸­ï¼‰
            for existing_id in existing_ids:
                if existing_id not in all_target_coins:
                    all_target_coins[existing_id] = {
                        "id": existing_id,
                        "name": existing_id,
                    }

            self.stats["total_coins"] = len(all_target_coins)

            # 5. æ‰¹é‡æ›´æ–°é‡ä»·æ•°æ®
            logger.info(f"ğŸ“¥ å¼€å§‹æ‰¹é‡æ›´æ–° {len(all_target_coins)} ä¸ªå¸ç§çš„é‡ä»·æ•°æ®")

            updated_count = 0
            failed_count = 0

            with tqdm(
                total=len(all_target_coins),
                desc="æ›´æ–°é‡ä»·æ•°æ®",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                ncols=100,
                leave=False,
                position=0,
            ) as pbar:
                for coin_id, coin_info in all_target_coins.items():
                    try:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¨³å®šå¸
                        if self.checker.is_stablecoin(coin_info.get("symbol", "")):
                            pbar.update(1)
                            pbar.set_postfix({"çŠ¶æ€": "è·³è¿‡ç¨³å®šå¸"})
                            continue

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                        is_new_coin = coin_id in [c["id"] for c in new_coins]
                        needs_update, last_date = self.needs_update(coin_id)

                        if needs_update:
                            success = self.download_coin_data(
                                coin_id=coin_id,
                                is_new_coin=is_new_coin,
                                from_date=last_date,
                            )

                            if success:
                                updated_count += 1
                                if is_new_coin:
                                    self.new_coins.append(coin_id)
                                else:
                                    self.updated_coins.append(coin_id)
                            else:
                                failed_count += 1

                            self.stats["total_api_calls"] += 1

                            # APIé™æµå»¶è¿Ÿ
                            time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])

                        pbar.update(1)
                        pbar.set_postfix(
                            {
                                "æ›´æ–°": updated_count,
                                "å¤±è´¥": failed_count,
                                "å½“å‰": coin_id[:20],
                            }
                        )

                    except Exception as e:
                        error_msg = f"å¤„ç†å¸ç§ {coin_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
                        logger.error(error_msg)
                        self.errors.append(error_msg)
                        failed_count += 1

                        pbar.update(1)

            self.stats["updated_coins"] = updated_count
            self.stats["failed_coins"] = failed_count

            # 6. æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ®
            self.update_stablecoin_metadata()

            # 7. æ›´æ–°READMEæ—¶é—´æˆ³
            self.update_readme_timestamp()

        except Exception as e:
            error_msg = f"æ›´æ–°æµç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

        finally:
            self.stats["end_time"] = datetime.now()

            # 8. ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
            report = self.generate_update_report()
            logger.info(report)

            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = (
                Path("logs")
                / f"price_update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            )
            report_file.write_text(report, encoding="utf-8")

            logger.info(f"ğŸ“‹ æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
            logger.info("ğŸ‰ é‡ä»·æ•°æ®æ›´æ–°æµç¨‹å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ›´æ–°åŠ å¯†è´§å¸é‡ä»·æ•°æ®")
    parser.add_argument("--top-n", type=int, default=500, help="å¸‚å€¼å‰Nå (é»˜è®¤: 500)")
    parser.add_argument(
        "--batch-size", type=int, default=50, help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 50)"
    )
    parser.add_argument(
        "--delay", type=float, default=0.13, help="APIè°ƒç”¨å»¶è¿Ÿç§’æ•° (é»˜è®¤: 0.13)"
    )

    args = parser.parse_args()

    # æ›´æ–°é…ç½®
    RATE_LIMIT_CONFIG["batch_size"] = args.batch_size
    RATE_LIMIT_CONFIG["delay_seconds"] = args.delay

    print(f"ğŸ” é‡ä»·æ•°æ®æ›´æ–°å·¥å…·")
    print(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
    print(f"   - ç›®æ ‡å¸ç§æ•°: å‰{args.top_n}åï¼ˆç”¨äºå‘ç°æ–°å¸ç§ï¼‰")
    print(f"   - æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
    print(f"   - APIè°ƒç”¨å»¶è¿Ÿ: {args.delay}ç§’")
    print(f"   - é¢„ä¼°APIè°ƒç”¨é¢‘ç‡: {60/args.delay:.1f}æ¬¡/åˆ†é’Ÿ")
    print("")

    # åˆ›å»ºæ›´æ–°å™¨å¹¶è¿è¡Œ
    updater = PriceDataUpdater()
    updater.run(top_n=args.top_n)


if __name__ == "__main__":
    main()
