"""
æ‰¹é‡æ›´æ–°åŠ å¯†è´§å¸é‡ä»·æ•°æ®

è¯¥è„šæœ¬ä¼šï¼š
1. è·å–å¸‚å€¼å‰Nåçš„åŠ å¯†è´§å¸
2. ä¸ç°æœ‰coinsç›®å½•å¯¹æ¯”ï¼Œå‘ç°æ–°å¸ç§
3. æ£€æµ‹æ¯ä¸ªå¸ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ
4. å¢é‡ä¸‹è½½ç¼ºå¤±çš„é‡ä»·æ•°æ®
5. æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®
6. ç”Ÿæˆæ›´æ–°æŠ¥å‘Šå¹¶æ›´æ–°README
"""

import logging
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

import pandas as pd
from pandas.errors import OutOfBoundsDatetime
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from examples.stablecoin_checker import StablecoinChecker
from examples.wrapped_coin_checker import WrappedCoinChecker
from src.api.coingecko import CoinGeckoAPI
from src.data.batch_downloader import create_batch_downloader

# APIé™æµé…ç½® (CoinGecko Analystè®¡åˆ’)
RATE_LIMIT_CONFIG = {
    "calls_per_minute": 500,
    "delay_seconds": 0.13,  # 500/min = 8.33/sec â‰ˆ 0.12sé—´éš”ï¼Œä¿é™©èµ·è§ç”¨0.13s
    "batch_size": 50,  # æ¯æ‰¹å¤„ç†å¸ç§æ•°
    "max_retries": 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
}

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
Path("logs").mkdir(exist_ok=True)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("logs/price_data_update.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class PriceDataUpdater:
    """é‡ä»·æ•°æ®æ›´æ–°å™¨"""

    def __init__(self, api=None, downloader=None, checker=None, wrapped_checker=None):
        """
        åˆå§‹åŒ–é‡ä»·æ•°æ®æ›´æ–°å™¨

        Args:
            api: CoinGeckoAPI å®ä¾‹
            downloader: BatchDownloader å®ä¾‹
            checker: StablecoinChecker å®ä¾‹
            wrapped_checker: WrappedCoinChecker å®ä¾‹
        """
        self.api = api or CoinGeckoAPI()
        self.downloader = downloader or create_batch_downloader()
        self.checker = checker or StablecoinChecker()
        self.wrapped_checker = wrapped_checker or WrappedCoinChecker()
        self.coins_dir = Path("data/coins")
        self.metadata_dir = Path("data/metadata")

        self.errors = []
        self.updated_coins = []
        self.new_coins = []

        self.stats = {
            "total_coins": 0,
            "native_coins": 0,
            "stablecoins": 0,
            "wrapped_coins": 0,
            "searched_coins": 0,
            "target_native_coins": 0,
            "new_coins": 0,
            "updated_coins": 0,
            "failed_coins": 0,
            "total_api_calls": 0,
            "start_time": None,
            "end_time": None,
        }

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        Path("logs").mkdir(exist_ok=True)

    def get_top_n_coins_by_market_cap(self, n: int = 500) -> List[Dict]:
        """
        è·å–å¸‚å€¼å‰Nåçš„åŠ å¯†è´§å¸

        Args:
            n: è·å–å‰Nå

        Returns:
            å¸ç§åˆ—è¡¨
        """
        logger.info(f"ğŸ” è·å–å¸‚å€¼å‰ {n} ååŠ å¯†è´§å¸")

        all_coins = []
        page = 1
        per_page = 250  # CoinGeckoå•é¡µæœ€å¤§å€¼

        with tqdm(desc="è·å–å¸‚å€¼æ’å", unit="é¡µ", leave=True) as pbar:
            while len(all_coins) < n:
                try:
                    logger.info(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µå¸‚åœºæ•°æ®...")

                    # è®¡ç®—æœ¬é¡µéœ€è¦è·å–çš„æ•°é‡
                    remaining = n - len(all_coins)
                    current_per_page = min(per_page, remaining)

                    coins = self.api.get_coins_markets(
                        vs_currency="usd",
                        order="market_cap_desc",
                        per_page=current_per_page,
                        page=page,
                    )

                    if not coins:
                        logger.warning(f"ç¬¬ {page} é¡µæœªè·å–åˆ°æ•°æ®ï¼Œåœæ­¢è·å–")
                        break

                    all_coins.extend(coins)
                    self.stats["total_api_calls"] += 1

                    pbar.update(1)
                    pbar.set_postfix(
                        {"å·²è·å–": len(all_coins), "ç›®æ ‡": n, "å½“å‰é¡µ": page}
                    )

                    page += 1

                    # APIé™æµå»¶è¿Ÿ
                    time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])

                except Exception as e:
                    error_msg = f"è·å–ç¬¬ {page} é¡µå¸‚åœºæ•°æ®å¤±è´¥: {e}"
                    logger.error(error_msg)
                    self.errors.append(error_msg)
                    break

        # ç¡®ä¿åªè¿”å›å‰Nå
        result = all_coins[:n]
        logger.info(f"âœ… æˆåŠŸè·å– {len(result)} ä¸ªå¸ç§çš„å¸‚å€¼æ’å")

        return result

    def get_top_n_native_coins_by_market_cap(
        self, target_native_coins: int = 510, max_search_range: int = 3000
    ) -> List[Dict]:
        """
        è·å–å¸‚å€¼å‰Nåçš„åŸç”Ÿå¸ç§ï¼Œè‡ªåŠ¨æ‰©å¤§æœç´¢èŒƒå›´ç›´åˆ°æ‰¾åˆ°è¶³å¤Ÿçš„åŸç”Ÿå¸

        Args:
            target_native_coins: ç›®æ ‡åŸç”Ÿå¸ç§æ•°é‡
            max_search_range: æœ€å¤§æœç´¢èŒƒå›´ï¼ˆé»˜è®¤3000ï¼Œç¡®ä¿èƒ½è¦†ç›–è¶³å¤Ÿçš„å¸ç§ï¼‰

        Returns:
            åŸç”Ÿå¸ç§åˆ—è¡¨
        """
        logger.info(f"ğŸ” è·å–å¸‚å€¼å‰ {target_native_coins} ååŸç”Ÿå¸ç§")

        native_coins = []
        # æ™ºèƒ½è®¾å®šåˆå§‹æœç´¢èŒƒå›´ï¼šç›®æ ‡æ•°é‡ + é¢„ä¼°çš„ç¨³å®šå¸/åŒ…è£…å¸æ•°é‡
        estimated_non_native = int(target_native_coins * 0.3)  # é¢„ä¼°30%ä¸ºéåŸç”Ÿå¸
        search_range = min(target_native_coins + estimated_non_native, max_search_range)

        while (
            len(native_coins) < target_native_coins and search_range <= max_search_range
        ):
            logger.info(
                f"æœç´¢å¸‚å€¼å‰ {search_range} åå¸ç§ä»¥æ‰¾åˆ° {target_native_coins} ä¸ªåŸç”Ÿå¸..."
            )

            # è·å–å¸‚å€¼æ’å
            all_coins = self.get_top_n_coins_by_market_cap(search_range)
            if not all_coins:
                break

            # è¿‡æ»¤å‡ºåŸç”Ÿå¸ç§
            native_coins = []
            stable_count = 0
            wrapped_count = 0

            for coin in all_coins:
                try:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç¨³å®šå¸æˆ–åŒ…è£…å¸
                    stable_result = self.checker.is_stablecoin(coin["id"])
                    wrapped_result = self.wrapped_checker.is_wrapped_coin(coin["id"])

                    # æå–å®é™…çš„å¸ƒå°”å€¼
                    is_stable = (
                        stable_result.get("is_stablecoin", False)
                        if isinstance(stable_result, dict)
                        else stable_result
                    )
                    is_wrapped = (
                        wrapped_result.get("is_wrapped_coin", False)
                        if isinstance(wrapped_result, dict)
                        else wrapped_result
                    )

                    if is_stable:
                        stable_count += 1
                    elif is_wrapped:
                        wrapped_count += 1
                    else:
                        native_coins.append(coin)

                    if len(native_coins) >= target_native_coins:
                        break
                except Exception as e:
                    logger.warning(f"æ£€æŸ¥å¸ç§ {coin['id']} æ—¶å‡ºé”™: {e}")
                    # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œæš‚æ—¶è®¤ä¸ºæ˜¯åŸç”Ÿå¸ç§
                    native_coins.append(coin)
                    if len(native_coins) >= target_native_coins:
                        break

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats["searched_coins"] = len(all_coins)
            self.stats["stablecoins"] = stable_count
            self.stats["wrapped_coins"] = wrapped_count
            self.stats["native_coins"] = len(native_coins)

            if len(native_coins) >= target_native_coins:
                break
            else:
                # å¦‚æœåŸç”Ÿå¸ç§ä¸è¶³ï¼Œæ™ºèƒ½æ‰©å¤§æœç´¢èŒƒå›´
                old_range = search_range
                # æ ¹æ®ç¼ºå£å¤§å°å†³å®šæ‰©å¤§å¹…åº¦
                shortage = target_native_coins - len(native_coins)
                if shortage > 200:
                    increment = 500  # ç¼ºå£å¤§æ—¶å¤§å¹…æ‰©å¤§
                elif shortage > 100:
                    increment = 300  # ä¸­ç­‰ç¼ºå£ä¸­ç­‰æ‰©å¤§
                else:
                    increment = 200  # å°ç¼ºå£å°å¹…æ‰©å¤§

                search_range = min(search_range + increment, max_search_range)

                if search_range == old_range:
                    # è¾¾åˆ°æœ€å¤§æœç´¢èŒƒå›´ï¼Œåœæ­¢
                    logger.warning(
                        f"è¾¾åˆ°æœ€å¤§æœç´¢èŒƒå›´ {max_search_range}ï¼Œä½†åªæ‰¾åˆ° {len(native_coins)} ä¸ªåŸç”Ÿå¸ç§"
                    )
                    break
                logger.info(
                    f"åŸç”Ÿå¸ç§ä¸è¶³ ({len(native_coins)}/{target_native_coins})ï¼Œæ‰©å¤§æœç´¢èŒƒå›´åˆ° {search_range}"
                )

        result = native_coins[:target_native_coins]
        self.stats["target_native_coins"] = len(result)
        logger.info(f"âœ… æˆåŠŸè·å– {len(result)} ä¸ªåŸç”Ÿå¸ç§")

        return result

    def get_existing_coin_ids(self) -> Set[str]:
        """
        è·å–ç°æœ‰coinsç›®å½•ä¸­çš„å¸ç§ID

        Returns:
            å¸ç§IDé›†åˆ
        """
        existing_ids = set()

        if self.coins_dir.exists():
            for csv_file in self.coins_dir.glob("*.csv"):
                coin_id = csv_file.stem
                existing_ids.add(coin_id)

        logger.info(f"ğŸ“‹ ç°æœ‰å¸ç§æ•°é‡: {len(existing_ids)}")
        return existing_ids

    def find_new_coins(
        self, top_coins: List[Dict], existing_ids: Set[str]
    ) -> List[Dict]:
        """
        æ‰¾å‡ºæ–°çš„å¸ç§

        Args:
            top_coins: å¸‚å€¼å‰Nåå¸ç§
            existing_ids: ç°æœ‰å¸ç§IDé›†åˆ

        Returns:
            æ–°å¸ç§åˆ—è¡¨
        """
        new_coins = []

        for coin in top_coins:
            coin_id = coin["id"]
            if coin_id not in existing_ids:
                new_coins.append(coin)

        logger.info(f"ğŸ†• å‘ç°æ–°å¸ç§: {len(new_coins)} ä¸ª")
        for coin in new_coins:
            logger.info(
                f"   - {coin['name']} ({coin['symbol'].upper()}) - å¸‚å€¼æ’å: {coin['market_cap_rank']}"
            )

        return new_coins

    def get_coin_last_date(self, coin_id: str) -> Optional[str]:
        """
        è·å–å¸ç§çš„æœ€æ–°æ•°æ®æ—¥æœŸ

        Args:
            coin_id: å¸ç§ID

        Returns:
            æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD) æˆ– None
        """
        csv_file = self.coins_dir / f"{coin_id}.csv"

        if not csv_file.exists():
            logger.debug(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ä¸å­˜åœ¨")
            return None

        try:
            df = pd.read_csv(csv_file)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—ï¼ˆå¯èƒ½æ˜¯timestampæˆ–dateï¼‰
            time_column = None
            if "date" in df.columns:
                time_column = "date"
            elif "timestamp" in df.columns:
                time_column = "timestamp"
            else:
                logger.warning(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ç¼ºå°‘æ—¶é—´åˆ—ï¼ˆdateæˆ–timestampï¼‰")
                return None

            if len(df) == 0:
                logger.warning(f"ğŸ“„ {coin_id}: CSVæ–‡ä»¶ä¸ºç©º")
                return None

            # è·å–æœ€æ–°æ—¥æœŸ
            if time_column == "timestamp":
                # å¦‚æœæ˜¯timestampï¼Œéœ€è¦æ­£ç¡®å¤„ç†å•ä½
                try:
                    # å°è¯•æ¯«ç§’å•ä½
                    df["date"] = pd.to_datetime(df["timestamp"], unit="ms").dt.strftime(
                        "%Y-%m-%d"
                    )
                    last_date = df["date"].max()
                except (ValueError, OutOfBoundsDatetime):
                    try:
                        # å°è¯•ç§’å•ä½
                        df["date"] = pd.to_datetime(
                            df["timestamp"], unit="s"
                        ).dt.strftime("%Y-%m-%d")
                        last_date = df["date"].max()
                    except (ValueError, OutOfBoundsDatetime):
                        logger.warning(f"ğŸ“„ {coin_id}: æ— æ³•è§£ætimestampæ ¼å¼")
                        return None
            else:
                last_date = df[time_column].max()

            logger.debug(f"ğŸ“„ {coin_id}: æœ€æ–°æ•°æ®æ—¥æœŸ {last_date}")
            return last_date

        except Exception as e:
            logger.warning(f"ğŸ“„ {coin_id}: è¯»å–CSVæ–‡ä»¶å¤±è´¥ - {e}")
            return None

    def needs_update(self, coin_id: str) -> Tuple[bool, Optional[str]]:
        """
        æ£€æŸ¥å¸ç§æ˜¯å¦éœ€è¦æ›´æ–°

        Args:
            coin_id: å¸ç§ID

        Returns:
            (æ˜¯å¦éœ€è¦æ›´æ–°, æœ€æ–°æ—¥æœŸ)
        """
        last_date = self.get_coin_last_date(coin_id)

        if last_date is None:
            return True, None  # æ–°å¸ç§ï¼Œéœ€è¦ä¸‹è½½å…¨éƒ¨æ•°æ®

        try:
            last_datetime = datetime.strptime(last_date, "%Y-%m-%d")
            today = datetime.now()

            # å¦‚æœæœ€æ–°æ•°æ®ä¸æ˜¯ä»Šå¤©ï¼Œåˆ™éœ€è¦æ›´æ–°
            if last_datetime.date() < today.date():
                return True, last_date

        except ValueError:
            logger.warning(f"è§£ææ—¥æœŸå¤±è´¥: {last_date}")
            return True, last_date

        return False, last_date

    def download_coin_data(
        self, coin_id: str, is_new_coin: bool = False, from_date: Optional[str] = None
    ) -> bool:
        """
        ä¸‹è½½å¸ç§çš„é‡ä»·æ•°æ®

        Args:
            coin_id: å¸ç§ID
            is_new_coin: æ˜¯å¦ä¸ºæ–°å¸ç§
            from_date: èµ·å§‹æ—¥æœŸ (å¢é‡æ›´æ–°æ—¶ä½¿ç”¨)

        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            if is_new_coin:
                # æ–°å¸ç§ï¼Œä¸‹è½½æœ€å¤§å¤©æ•°çš„å†å²æ•°æ®
                logger.info(f"ğŸ“¥ ä¸‹è½½æ–°å¸ç§ {coin_id} çš„å®Œæ•´å†å²æ•°æ®...")
                success = self.downloader.download_coin_data(
                    coin_id=coin_id, days="max", vs_currency="usd"
                )
            else:
                # ç°æœ‰å¸ç§ï¼Œå¢é‡æ›´æ–°
                if from_date:
                    # è®¡ç®—éœ€è¦æ›´æ–°çš„å¤©æ•°
                    from_datetime = datetime.strptime(from_date, "%Y-%m-%d")
                    today = datetime.now()
                    days_to_update = (today - from_datetime).days + 1

                    logger.info(
                        f"ğŸ“¥ å¢é‡æ›´æ–° {coin_id}ï¼Œä» {from_date} å¼€å§‹ï¼Œå…± {days_to_update} å¤©..."
                    )
                    success = self.downloader.download_coin_data(
                        coin_id=coin_id, days=str(days_to_update), vs_currency="usd"
                    )
                else:
                    # æ— æ³•ç¡®å®šèµ·å§‹æ—¥æœŸï¼Œé‡æ–°ä¸‹è½½å…¨éƒ¨æ•°æ®
                    logger.info(
                        f"ğŸ“¥ é‡æ–°ä¸‹è½½ {coin_id} çš„å®Œæ•´å†å²æ•°æ®ï¼ˆæ— æ³•ç¡®å®šå¢é‡èµ·å§‹ç‚¹ï¼‰..."
                    )
                    success = self.downloader.download_coin_data(
                        coin_id=coin_id, days="max", vs_currency="usd"
                    )

            if success:
                logger.info(f"âœ… {coin_id} æ•°æ®ä¸‹è½½æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ {coin_id} æ•°æ®ä¸‹è½½å¤±è´¥")
                return False

        except Exception as e:
            error_msg = f"ä¸‹è½½ {coin_id} æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)
            return False

    def update_stablecoin_metadata(self):
        """
        æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ® (å¤ç”¨å·²æœ‰æ•°æ®)
        """
        logger.info("ğŸ’° æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®...")

        try:
            # è·å–æ‰€æœ‰éœ€è¦å…ƒæ•°æ®çš„å¸ç§
            coin_ids = [f.stem for f in self.coins_dir.glob("*.csv")]

            # æ£€æŸ¥å“ªäº›å¸ç§ç¼ºå°‘å…ƒæ•°æ®
            missing_metadata = []
            for coin_id in coin_ids:
                metadata_file = self.metadata_dir / "coin_metadata" / f"{coin_id}.json"
                if not metadata_file.exists():
                    missing_metadata.append(coin_id)

            if missing_metadata:
                logger.info(
                    f"ğŸ”„ å‘ç° {len(missing_metadata)} ä¸ªå¸ç§ç¼ºå°‘å…ƒæ•°æ®ï¼Œå¼€å§‹æ›´æ–°..."
                )

                # æ‰¹é‡æ›´æ–°ç¼ºå¤±çš„å…ƒæ•°æ®
                results = self.downloader.batch_update_coin_metadata(
                    coin_ids=missing_metadata,
                    force=False,
                    delay_seconds=RATE_LIMIT_CONFIG["delay_seconds"],
                )

                success_count = sum(1 for success in results.values() if success)
                logger.info(
                    f"âœ… å…ƒæ•°æ®æ›´æ–°å®Œæˆ: {success_count}/{len(missing_metadata)} æˆåŠŸ"
                )

                self.stats["total_api_calls"] += len(missing_metadata)
            else:
                logger.info("âœ… æ‰€æœ‰å¸ç§å…ƒæ•°æ®éƒ½æ˜¯æœ€æ–°çš„")

            # é‡æ–°ç”Ÿæˆç¨³å®šå¸åˆ—è¡¨
            checker = StablecoinChecker()
            success = checker.export_stablecoins_csv()

            if success:
                logger.info("âœ… ç¨³å®šå¸åˆ—è¡¨æ›´æ–°æˆåŠŸ")
            else:
                logger.error("âŒ ç¨³å®šå¸åˆ—è¡¨æ›´æ–°å¤±è´¥")

            # é‡æ–°ç”ŸæˆåŒ…è£…å¸åˆ—è¡¨
            wrapped_checker = WrappedCoinChecker()
            success = wrapped_checker.export_wrapped_coins_csv()

            if success:
                logger.info("âœ… åŒ…è£…å¸åˆ—è¡¨æ›´æ–°æˆåŠŸ")
            else:
                logger.error("âŒ åŒ…è£…å¸åˆ—è¡¨æ›´æ–°å¤±è´¥")

        except Exception as e:
            error_msg = f"æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

    def generate_update_report(self) -> str:
        """
        ç”Ÿæˆæ›´æ–°æŠ¥å‘Š

        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        duration = self.stats["end_time"] - self.stats["start_time"]

        report = f"""
ğŸ” é‡ä»·æ•°æ®æ›´æ–°æŠ¥å‘Š
{'='*60}
ğŸ“Š å¸ç§åˆ†ç±»ç»Ÿè®¡:
   - æœç´¢èŒƒå›´: å‰{self.stats['searched_coins']}å
   - ç›®æ ‡åŸç”Ÿå¸ç§æ•°: {self.stats['target_native_coins']}
   - å‘ç°åŸç”Ÿå¸ç§: {self.stats['native_coins']}ä¸ª
   - å‘ç°ç¨³å®šå¸: {self.stats['stablecoins']}ä¸ª
   - å‘ç°åŒ…è£…å¸: {self.stats['wrapped_coins']}ä¸ª

ğŸ“ˆ å¤„ç†ç»Ÿè®¡:
   - å®é™…å¤„ç†å¸ç§æ•°: {self.stats['total_coins']}
   - æ–°å¸ç§æ•°: {self.stats['new_coins']}
   - æ›´æ–°å¸ç§æ•°: {self.stats['updated_coins']}
   - å¤±è´¥å¸ç§æ•°: {self.stats['failed_coins']}

âš¡ æ€§èƒ½ç»Ÿè®¡:
   - APIè°ƒç”¨æ¬¡æ•°: {self.stats['total_api_calls']}
   - æ€»è€—æ—¶: {duration}

ğŸ• æ—¶é—´ä¿¡æ¯:
   - å¼€å§‹æ—¶é—´: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
   - ç»“æŸæ—¶é—´: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}

{'âŒ é”™è¯¯ä¿¡æ¯:' if self.errors else 'âœ… æ— é”™è¯¯'}
"""

        if self.errors:
            for i, error in enumerate(self.errors, 1):
                report += f"   {i}. {error}\n"

        return report

    def update_readme_timestamp(self):
        """
        æ›´æ–°README.mdä¸­çš„æœ€è¿‘æ›´æ–°æ—¶é—´
        """
        readme_path = Path("README.md")

        if not readme_path.exists():
            logger.warning("README.md æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ—¶é—´æˆ³æ›´æ–°")
            return

        try:
            content = readme_path.read_text(encoding="utf-8")
            today = datetime.now().strftime("%Y-%m-%d")

            # æŸ¥æ‰¾å¹¶æ›¿æ¢æ›´æ–°æ—¶é—´
            import re

            pattern = r"\(æœ€è¿‘æ›´æ–°: \d{4}-\d{2}-\d{2}\)"
            replacement = f"(æœ€è¿‘æ›´æ–°: {today})"

            if re.search(pattern, content):
                new_content = re.sub(pattern, replacement, content)
                readme_path.write_text(new_content, encoding="utf-8")
                logger.info(f"âœ… README.md æ›´æ–°æ—¶é—´å·²æ›´æ–°ä¸º: {today}")
            else:
                logger.warning("README.md ä¸­æœªæ‰¾åˆ°æ›´æ–°æ—¶é—´æ ¼å¼ï¼Œè·³è¿‡æ›´æ–°")

        except Exception as e:
            error_msg = f"æ›´æ–°README.mdæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

    def run(self, top_n: int = 600, native_coins: int = 510) -> None:
        """
        æ‰§è¡Œå®Œæ•´çš„é‡ä»·æ•°æ®æ›´æ–°æµç¨‹

        Args:
            top_n: åˆå§‹æœç´¢èŒƒå›´å»ºè®®å€¼ (å·²å¼ƒç”¨ï¼Œç°åœ¨ä¼šè‡ªåŠ¨è®¡ç®—)
            native_coins: ç›®æ ‡åŸç”Ÿå¸ç§æ•°é‡
        """
        logger.info(f"ğŸš€ å¼€å§‹é‡ä»·æ•°æ®æ›´æ–°æµç¨‹ (å‰{native_coins}ååŸç”Ÿå¸)")
        logger.info("=" * 60)

        self.stats["start_time"] = datetime.now()

        try:
            # 1. è·å–å¸‚å€¼å‰NååŸç”Ÿå¸ç§ (è‡ªåŠ¨è®¡ç®—åˆé€‚çš„æœç´¢èŒƒå›´)
            max_search_range = max(native_coins * 2, 2000)  # ç¡®ä¿æœç´¢èŒƒå›´è¶³å¤Ÿå¤§
            native_coins_list = self.get_top_n_native_coins_by_market_cap(
                native_coins, max_search_range
            )
            if not native_coins_list:
                logger.error("âŒ æ— æ³•è·å–åŸç”Ÿå¸ç§æ•°æ®")
                return

            # 2. è·å–ç°æœ‰å¸ç§ID
            existing_ids = self.get_existing_coin_ids()

            # 3. æ‰¾å‡ºæ–°å¸ç§
            new_coins = self.find_new_coins(native_coins_list, existing_ids)
            self.stats["new_coins"] = len(new_coins)

            # 4. æ‰€æœ‰éœ€è¦å¤„ç†çš„å¸ç§å°±æ˜¯è¿™äº›åŸç”Ÿå¸ç§
            all_target_coins = {coin["id"]: coin for coin in native_coins_list}

            self.stats["total_coins"] = len(all_target_coins)

            # 5. æ‰¹é‡æ›´æ–°é‡ä»·æ•°æ®
            logger.info(f"ğŸ“¥ å¼€å§‹æ‰¹é‡æ›´æ–° {len(all_target_coins)} ä¸ªå¸ç§çš„é‡ä»·æ•°æ®")

            updated_count = 0
            failed_count = 0

            with tqdm(
                total=len(all_target_coins),
                desc="æ›´æ–°é‡ä»·æ•°æ®",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                ncols=100,
                leave=False,
                position=0,
            ) as pbar:
                for coin_id, coin_info in all_target_coins.items():
                    try:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¨³å®šå¸
                        stable_result = self.checker.is_stablecoin(
                            coin_info.get("symbol", "")
                        )
                        is_stable = (
                            stable_result.get("is_stablecoin", False)
                            if isinstance(stable_result, dict)
                            else stable_result
                        )

                        if is_stable:
                            pbar.update(1)
                            pbar.set_postfix({"çŠ¶æ€": "è·³è¿‡ç¨³å®šå¸"})
                            continue

                        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒ…è£…å¸
                        if self.wrapped_checker.is_wrapped_coin(coin_id)[
                            "is_wrapped_coin"
                        ]:
                            pbar.update(1)
                            pbar.set_postfix({"çŠ¶æ€": "è·³è¿‡åŒ…è£…å¸"})
                            continue

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                        is_new_coin = coin_id in [c["id"] for c in new_coins]
                        needs_update, last_date = self.needs_update(coin_id)

                        if needs_update:
                            success = self.download_coin_data(
                                coin_id=coin_id,
                                is_new_coin=is_new_coin,
                                from_date=last_date,
                            )

                            if success:
                                updated_count += 1
                                if is_new_coin:
                                    self.new_coins.append(coin_id)
                                else:
                                    self.updated_coins.append(coin_id)
                            else:
                                failed_count += 1

                            self.stats["total_api_calls"] += 1

                            # APIé™æµå»¶è¿Ÿ
                            time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])

                        pbar.update(1)
                        pbar.set_postfix(
                            {
                                "æ›´æ–°": updated_count,
                                "å¤±è´¥": failed_count,
                                "å½“å‰": coin_id[:20],
                            }
                        )

                    except Exception as e:
                        error_msg = f"å¤„ç†å¸ç§ {coin_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
                        logger.error(error_msg)
                        self.errors.append(error_msg)
                        failed_count += 1

                        pbar.update(1)

            self.stats["updated_coins"] = updated_count
            self.stats["failed_coins"] = failed_count

            # 6. æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®
            self.update_stablecoin_metadata()

            # 7. æ›´æ–°READMEæ—¶é—´æˆ³
            self.update_readme_timestamp()

        except Exception as e:
            error_msg = f"æ›´æ–°æµç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(error_msg)
            self.errors.append(error_msg)

        finally:
            self.stats["end_time"] = datetime.now()

            # 8. ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
            report = self.generate_update_report()
            logger.info(report)

            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = (
                Path("logs")
                / f"price_update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            )
            report_file.write_text(report, encoding="utf-8")

            logger.info(f"ğŸ“‹ æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
            logger.info("ğŸ‰ é‡ä»·æ•°æ®æ›´æ–°æµç¨‹å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ›´æ–°åŠ å¯†è´§å¸é‡ä»·æ•°æ®")
    parser.add_argument(
        "--top-n", type=int, default=600, help="å¸‚å€¼å‰Nåæœç´¢èŒƒå›´ (é»˜è®¤: 600)"
    )
    parser.add_argument(
        "--native-coins", type=int, default=510, help="ç›®æ ‡åŸç”Ÿå¸ç§æ•°é‡ (é»˜è®¤: 510)"
    )
    parser.add_argument(
        "--batch-size", type=int, default=50, help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 50)"
    )
    parser.add_argument(
        "--delay", type=float, default=0.13, help="APIè°ƒç”¨å»¶è¿Ÿç§’æ•° (é»˜è®¤: 0.13)"
    )

    args = parser.parse_args()

    # æ›´æ–°é…ç½®
    RATE_LIMIT_CONFIG["batch_size"] = args.batch_size
    RATE_LIMIT_CONFIG["delay_seconds"] = args.delay

    print(f"ğŸ” é‡ä»·æ•°æ®æ›´æ–°å·¥å…·")
    print(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
    print(f"   - ç›®æ ‡åŸç”Ÿå¸ç§æ•°: {args.native_coins}")
    print(f"   - æœç´¢èŒƒå›´: åŠ¨æ€æ‰©å±•ï¼ˆè‡ªåŠ¨è°ƒæ•´ç›´åˆ°æ‰¾åˆ°è¶³å¤Ÿçš„åŸç”Ÿå¸ï¼‰")
    print(f"   - æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
    print(f"   - APIè°ƒç”¨å»¶è¿Ÿ: {args.delay}ç§’")
    print(f"   - é¢„ä¼°APIè°ƒç”¨é¢‘ç‡: {60/args.delay:.1f}æ¬¡/åˆ†é’Ÿ")
    print("")

    # åˆ›å»ºæ›´æ–°å™¨å¹¶è¿è¡Œ
    updater = PriceDataUpdater()
    updater.run(top_n=args.top_n, native_coins=args.native_coins)


if __name__ == "__main__":
    main()
