#!/usr/bin/env python3
"""
å¢é‡æ¯æ—¥æ•°æ®æ›´æ–°å™¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ£€æµ‹æ–°å¸ç§ (å¯¹æ¯”å·²æœ‰æ•°æ® vs å½“å‰å¸‚å€¼æ’å)
2. ä¸‹è½½æ–°å¸ç§å®Œæ•´å†å²æ•°æ®
3. æ™ºèƒ½æ’å…¥åˆ°ç°æœ‰æ¯æ—¥æ±‡æ€»æ–‡ä»¶ä¸­
4. ç»´æŠ¤æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§

è®¾è®¡åŸåˆ™ï¼š
- æœ€å°å½±å“ï¼šåªæ›´æ–°å¿…è¦çš„æ–‡ä»¶
- æ•°æ®å®Œæ•´æ€§ï¼šç¡®ä¿æ‰€æœ‰æ’å…¥æ“ä½œçš„åŸå­æ€§
- æ€§èƒ½ä¼˜åŒ–ï¼šå¹¶è¡Œå¤„ç†å’Œæ™ºèƒ½ç¼“å­˜
- é”™è¯¯æ¢å¤ï¼šæ”¯æŒå›æ»šå’Œé‡è¯•æœºåˆ¶
"""

import logging
import json
from datetime import date, datetime, timedelta
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import tempfile
import shutil

import pandas as pd

from ..api.coingecko import CoinGeckoAPI
from ..downloaders.batch_downloader import create_batch_downloader
from ..updaters.price_updater import MarketDataFetcher

logger = logging.getLogger(__name__)


class IncrementalDailyUpdater:
    """å¢é‡æ¯æ—¥æ•°æ®æ›´æ–°å™¨

    èŒè´£ï¼š
    1. æ–°å¸ç§æ£€æµ‹
    2. å†å²æ•°æ®ä¸‹è½½
    3. æ¯æ—¥æ–‡ä»¶æ›´æ–°
    4. æ“ä½œæ—¥å¿—è®°å½•
    """

    def __init__(
        self,
        coins_dir: str = "data/coins",
        daily_dir: str = "data/daily/daily_files",
        backup_enabled: bool = True,
    ):
        """
        åˆå§‹åŒ–å¢é‡æ›´æ–°å™¨

        Args:
            coins_dir: å¸ç§æ•°æ®ç›®å½•
            daily_dir: æ¯æ—¥æ±‡æ€»æ•°æ®ç›®å½•
            backup_enabled: æ˜¯å¦å¯ç”¨å¤‡ä»½åŠŸèƒ½
        """
        self.coins_dir = Path(coins_dir)
        self.daily_dir = Path(daily_dir)
        self.backup_enabled = backup_enabled

        # åˆå§‹åŒ–ä¾èµ–ç»„ä»¶
        self.downloader = create_batch_downloader()
        api = CoinGeckoAPI()
        self.market_fetcher = MarketDataFetcher(api)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.daily_dir.mkdir(parents=True, exist_ok=True)

        # æ“ä½œæ—¥å¿—æ–‡ä»¶
        self.operation_log = Path("logs/incremental_daily_operations.jsonl")
        self.operation_log.parent.mkdir(exist_ok=True)

        logger.info("å¢é‡æ¯æ—¥æ•°æ®æ›´æ–°å™¨åˆå§‹åŒ–å®Œæˆ")

    def get_existing_coins(self) -> Set[str]:
        """è·å–å·²æœ‰çš„å¸ç§åˆ—è¡¨"""
        existing = set()
        for csv_file in self.coins_dir.glob("*.csv"):
            existing.add(csv_file.stem)
        logger.debug(f"å‘ç° {len(existing)} ä¸ªå·²æœ‰å¸ç§")
        return existing

    def get_current_market_coins(self, top_n: int = 1000) -> Set[str]:
        """è·å–å½“å‰å¸‚å€¼å‰Nåå¸ç§"""
        logger.info(f"è·å–å½“å‰å¸‚å€¼å‰ {top_n} åå¸ç§...")
        try:
            market_data = self.market_fetcher.get_top_coins(top_n)
            coin_ids = {coin["id"] for coin in market_data}
            logger.info(f"æˆåŠŸè·å– {len(coin_ids)} ä¸ªå¸‚å€¼æ’åå¸ç§")
            return coin_ids
        except Exception as e:
            logger.error(f"è·å–å¸‚å€¼æ’åå¤±è´¥: {e}")
            return set()

    def detect_new_coins(self, top_n: int = 1000) -> List[str]:
        """æ£€æµ‹æ–°å¸ç§

        Returns:
            æ–°å¸ç§IDåˆ—è¡¨
        """
        logger.info("å¼€å§‹æ£€æµ‹æ–°å¸ç§...")

        existing = self.get_existing_coins()
        current = self.get_current_market_coins(top_n)

        if not current:
            logger.warning("æ— æ³•è·å–å½“å‰å¸‚å€¼æ’åï¼Œè·³è¿‡æ–°å¸ç§æ£€æµ‹")
            return []

        new_coins = current - existing

        if new_coins:
            logger.info(f"ğŸ†• å‘ç° {len(new_coins)} ä¸ªæ–°å¸ç§:")
            for coin in sorted(new_coins):
                logger.info(f"   - {coin}")
        else:
            logger.info("âœ… æ²¡æœ‰å‘ç°æ–°å¸ç§")

        return list(new_coins)

    def download_new_coin_history(self, coin_id: str) -> bool:
        """ä¸‹è½½æ–°å¸ç§çš„å®Œæ•´å†å²æ•°æ®

        Args:
            coin_id: å¸ç§ID

        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {coin_id} çš„å®Œæ•´å†å²æ•°æ®...")

        try:
            # ä½¿ç”¨ max days è·å–å®Œæ•´å†å²
            success = self.downloader.download_coin_data(coin_id, days="max")

            if success:
                logger.info(f"âœ… {coin_id} å†å²æ•°æ®ä¸‹è½½æˆåŠŸ")
                # è®°å½•æ“ä½œæ—¥å¿—
                self._log_operation("download", coin_id, success=True)
            else:
                logger.error(f"âŒ {coin_id} å†å²æ•°æ®ä¸‹è½½å¤±è´¥")
                self._log_operation(
                    "download", coin_id, success=False, error="ä¸‹è½½å¤±è´¥"
                )

            return success

        except Exception as e:
            error_msg = f"ä¸‹è½½ {coin_id} å†å²æ•°æ®æ—¶å‡ºé”™: {e}"
            logger.error(error_msg)
            self._log_operation("download", coin_id, success=False, error=str(e))
            return False

    def load_coin_data(self, coin_id: str) -> Optional[pd.DataFrame]:
        """åŠ è½½å¸ç§æ•°æ®

        Args:
            coin_id: å¸ç§ID

        Returns:
            å¸ç§æ•°æ®DataFrameï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        csv_path = self.coins_dir / f"{coin_id}.csv"
        if not csv_path.exists():
            logger.debug(f"å¸ç§æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return None

        try:
            df = pd.read_csv(csv_path)

            # æ•°æ®éªŒè¯
            required_columns = ["timestamp", "price", "market_cap"]
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                logger.error(f"{coin_id} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return None

            # è½¬æ¢æ—¥æœŸ
            df["date"] = pd.to_datetime(df["timestamp"], unit="ms").dt.date
            df["coin_id"] = coin_id

            # æ•°æ®æ¸…æ´—ï¼šç§»é™¤æ— æ•ˆè®°å½•
            original_len = len(df)
            df = df.dropna(subset=["price", "market_cap"])
            df = df[(df["price"] > 0) & (df["market_cap"] > 0)]

            if len(df) < original_len:
                logger.warning(f"{coin_id} æ¸…ç†äº† {original_len - len(df)} æ¡æ— æ•ˆè®°å½•")

            logger.debug(f"æˆåŠŸåŠ è½½ {coin_id} æ•°æ®: {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            logger.error(f"åŠ è½½ {coin_id} æ•°æ®å¤±è´¥: {e}")
            return None

    def get_existing_daily_dates(self) -> Set[date]:
        """è·å–å·²æœ‰çš„æ¯æ—¥æ•°æ®æ–‡ä»¶æ—¥æœŸ"""
        dates = set()

        # æ‰«æåˆ†å±‚ç»“æ„: YYYY/MM/YYYY-MM-DD.csv
        for year_dir in self.daily_dir.iterdir():
            if year_dir.is_dir() and year_dir.name.isdigit():
                for month_dir in year_dir.iterdir():
                    if month_dir.is_dir() and month_dir.name.isdigit():
                        for csv_file in month_dir.glob("*.csv"):
                            try:
                                file_date = datetime.strptime(
                                    csv_file.stem, "%Y-%m-%d"
                                ).date()
                                dates.add(file_date)
                            except ValueError:
                                continue

        logger.debug(f"å‘ç° {len(dates)} ä¸ªå·²æœ‰æ¯æ—¥æ•°æ®æ–‡ä»¶")
        return dates

    def _backup_daily_file(self, filepath: Path) -> Optional[Path]:
        """å¤‡ä»½æ¯æ—¥æ•°æ®æ–‡ä»¶

        Args:
            filepath: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„

        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        if not self.backup_enabled or not filepath.exists():
            return None

        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_dir = filepath.parent / ".backup"
            backup_dir.mkdir(exist_ok=True)

            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"{filepath.stem}_{timestamp}.csv"
            backup_path = backup_dir / backup_filename

            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(filepath, backup_path)
            logger.debug(f"å·²å¤‡ä»½æ–‡ä»¶: {backup_path}")
            return backup_path

        except Exception as e:
            logger.warning(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return None

    def insert_coin_into_daily_file(self, target_date: date, coin_data: Dict) -> bool:
        """å°†å¸ç§æ•°æ®æ’å…¥åˆ°æŒ‡å®šæ—¥æœŸçš„æ¯æ—¥æ–‡ä»¶ä¸­

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ
            coin_data: å¸ç§æ•°æ®å­—å…¸

        Returns:
            æ˜¯å¦æ’å…¥æˆåŠŸ
        """
        try:
            # æ„é€ æ–‡ä»¶è·¯å¾„
            year_dir = self.daily_dir / str(target_date.year)
            month_dir = year_dir / f"{target_date.month:02d}"
            filepath = month_dir / f"{target_date}.csv"

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            month_dir.mkdir(parents=True, exist_ok=True)

            # å¤‡ä»½ç°æœ‰æ–‡ä»¶
            backup_path = self._backup_daily_file(filepath)

            try:
                if filepath.exists():
                    # è¯»å–ç°æœ‰æ–‡ä»¶
                    df = pd.read_csv(filepath)

                    # æ£€æŸ¥å¸ç§æ˜¯å¦å·²å­˜åœ¨
                    if coin_data["coin_id"] in df["coin_id"].values:
                        logger.debug(
                            f"{coin_data['coin_id']} åœ¨ {target_date} å·²å­˜åœ¨ï¼Œè·³è¿‡"
                        )
                        return True

                    # æ·»åŠ æ–°å¸ç§æ•°æ®
                    new_row = pd.DataFrame([coin_data])
                    df = pd.concat([df, new_row], ignore_index=True)

                else:
                    # åˆ›å»ºæ–°æ–‡ä»¶
                    df = pd.DataFrame([coin_data])

                # é‡æ–°æ’åºå¹¶æ›´æ–°æ’å
                df = df.sort_values("market_cap", ascending=False).reset_index(
                    drop=True
                )
                df["rank"] = range(1, len(df) + 1)

                # ä¿å­˜æ–‡ä»¶
                df.to_csv(filepath, index=False, float_format="%.6f")

                logger.info(
                    f"âœ… å·²å°† {coin_data['coin_id']} æ’å…¥åˆ° {target_date} (æ’å: {df[df['coin_id'] == coin_data['coin_id']]['rank'].iloc[0]})"
                )

                # è®°å½•æ“ä½œæ—¥å¿—
                self._log_operation(
                    "insert",
                    coin_data["coin_id"],
                    success=True,
                    target_date=str(target_date),
                    rank=int(df[df["coin_id"] == coin_data["coin_id"]]["rank"].iloc[0]),
                )

                return True

            except Exception as e:
                # å¦‚æœæœ‰å¤‡ä»½ï¼Œå°è¯•æ¢å¤
                if backup_path and backup_path.exists():
                    try:
                        shutil.copy2(backup_path, filepath)
                        logger.warning(f"æ“ä½œå¤±è´¥ï¼Œå·²ä»å¤‡ä»½æ¢å¤: {filepath}")
                    except Exception as restore_error:
                        logger.error(f"æ¢å¤å¤‡ä»½å¤±è´¥: {restore_error}")

                raise e

        except Exception as e:
            error_msg = f"æ’å…¥ {coin_data['coin_id']} åˆ° {target_date} å¤±è´¥: {e}"
            logger.error(error_msg)
            self._log_operation(
                "insert",
                coin_data["coin_id"],
                success=False,
                error=str(e),
                target_date=str(target_date),
            )
            return False

    def integrate_new_coin_into_daily_files(self, coin_id: str) -> Tuple[int, int]:
        """å°†æ–°å¸ç§æ•°æ®é›†æˆåˆ°æ‰€æœ‰ç›¸å…³çš„æ¯æ—¥æ–‡ä»¶ä¸­

        Args:
            coin_id: å¸ç§ID

        Returns:
            (æˆåŠŸæ’å…¥å¤©æ•°, æ€»å°è¯•å¤©æ•°)
        """
        logger.info(f"ğŸ”„ å¼€å§‹é›†æˆ {coin_id} åˆ°æ¯æ—¥æ–‡ä»¶...")

        # åŠ è½½å¸ç§æ•°æ®
        coin_df = self.load_coin_data(coin_id)
        if coin_df is None:
            logger.error(f"æ— æ³•åŠ è½½ {coin_id} æ•°æ®")
            return 0, 0

        # è·å–å·²æœ‰çš„æ¯æ—¥æ–‡ä»¶æ—¥æœŸ
        existing_dates = self.get_existing_daily_dates()

        # æ‰¾åˆ°å¸ç§æ•°æ®ä¸å·²æœ‰æ—¥æœŸçš„äº¤é›†
        coin_dates = set(coin_df["date"].unique())
        relevant_dates = existing_dates.intersection(coin_dates)

        total_attempts = len(relevant_dates)
        if total_attempts == 0:
            logger.warning(f"{coin_id} æ•°æ®ä¸ç°æœ‰æ¯æ—¥æ–‡ä»¶æ— äº¤é›†")
            return 0, 0

        logger.info(
            f"{coin_id} æœ‰ {len(coin_dates)} å¤©æ•°æ®ï¼Œå…¶ä¸­ {total_attempts} å¤©ä¸å·²æœ‰æ–‡ä»¶é‡å "
        )

        # é€æ—¥æ’å…¥
        successful_insertions = 0

        for target_date in sorted(relevant_dates):
            # è·å–è¯¥æ—¥æœŸçš„å¸ç§æ•°æ®
            day_data = coin_df[coin_df["date"] == target_date]
            if day_data.empty:
                continue

            # å–æœ€æ–°è®°å½•ï¼ˆé˜²æ­¢åŒæ—¥å¤šæ¡è®°å½•ï¼‰
            latest_record = day_data.iloc[-1]

            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if (
                pd.isna(latest_record["price"])
                or latest_record["price"] <= 0
                or pd.isna(latest_record["market_cap"])
                or latest_record["market_cap"] <= 0
            ):
                logger.debug(f"{coin_id} åœ¨ {target_date} çš„æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                continue

            # æ„é€ æ•°æ®è®°å½•
            coin_data = {
                "timestamp": int(latest_record["timestamp"]),
                "price": float(latest_record["price"]),
                "volume": (
                    float(latest_record["volume"])
                    if pd.notna(latest_record["volume"])
                    else 0.0
                ),
                "market_cap": float(latest_record["market_cap"]),
                "date": target_date,
                "coin_id": coin_id,
            }

            # æ’å…¥åˆ°æ¯æ—¥æ–‡ä»¶
            if self.insert_coin_into_daily_file(target_date, coin_data):
                successful_insertions += 1

        success_rate = (
            (successful_insertions / total_attempts * 100) if total_attempts > 0 else 0
        )
        logger.info(
            f"âœ… {coin_id} é›†æˆå®Œæˆ: {successful_insertions}/{total_attempts} å¤©æˆåŠŸ ({success_rate:.1f}%)"
        )

        return successful_insertions, total_attempts

    def _log_operation(self, operation: str, coin_id: str, success: bool, **kwargs):
        """è®°å½•æ“ä½œæ—¥å¿—

        Args:
            operation: æ“ä½œç±»å‹ (download, insert, etc.)
            coin_id: å¸ç§ID
            success: æ˜¯å¦æˆåŠŸ
            **kwargs: å…¶ä»–ä¿¡æ¯
        """
        try:
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "operation": operation,
                "coin_id": coin_id,
                "success": success,
                **kwargs,
            }

            with open(self.operation_log, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry) + "\n")

        except Exception as e:
            logger.warning(f"è®°å½•æ“ä½œæ—¥å¿—å¤±è´¥: {e}")

    def update_with_new_coins(
        self, top_n: int = 1000, max_workers: int = 3, dry_run: bool = False
    ) -> Dict[str, Dict]:
        """æ£€æµ‹å¹¶é›†æˆæ–°å¸ç§çš„å®Œæ•´æµç¨‹

        Args:
            top_n: ç›‘æ§çš„å¸‚å€¼æ’åèŒƒå›´
            max_workers: å¹¶è¡Œä¸‹è½½çš„å·¥ä½œçº¿ç¨‹æ•°
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…ä¿®æ”¹æ–‡ä»¶ï¼‰

        Returns:
            æ“ä½œç»“æœå­—å…¸
        """
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹å¢é‡æ¯æ—¥æ•°æ®æ›´æ–°")
        logger.info(f"ç›‘æ§èŒƒå›´: å‰ {top_n} å")
        logger.info(f"å¹¶è¡Œçº¿ç¨‹: {max_workers}")
        logger.info(f"è¯•è¿è¡Œæ¨¡å¼: {'æ˜¯' if dry_run else 'å¦'}")
        logger.info("=" * 60)

        results = {
            "summary": {
                "start_time": start_time.isoformat(),
                "top_n": top_n,
                "dry_run": dry_run,
            },
            "new_coins": [],
            "download_results": {},
            "integration_results": {},
        }

        try:
            # 1. æ£€æµ‹æ–°å¸ç§
            new_coins = self.detect_new_coins(top_n)
            results["new_coins"] = new_coins

            if not new_coins:
                logger.info("âœ… æ²¡æœ‰å‘ç°æ–°å¸ç§ï¼Œæ— éœ€æ›´æ–°")
                results["summary"]["status"] = "no_new_coins"
                return results

            if dry_run:
                logger.info(
                    f"ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šå‘ç° {len(new_coins)} ä¸ªæ–°å¸ç§ï¼Œå®é™…è¿è¡Œæ—¶å°†ä¼šä¸‹è½½å¹¶é›†æˆ"
                )
                results["summary"]["status"] = "dry_run_complete"
                return results

            # 2. ä¸‹è½½æ–°å¸ç§å†å²æ•°æ®
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {len(new_coins)} ä¸ªæ–°å¸ç§çš„å†å²æ•°æ®...")

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_coin = {
                    executor.submit(self.download_new_coin_history, coin): coin
                    for coin in new_coins
                }

                for future in as_completed(future_to_coin):
                    coin = future_to_coin[future]
                    try:
                        success = future.result()
                        results["download_results"][coin] = {
                            "success": success,
                            "error": None,
                        }
                    except Exception as e:
                        logger.error(f"ä¸‹è½½ {coin} æ—¶å‡ºé”™: {e}")
                        results["download_results"][coin] = {
                            "success": False,
                            "error": str(e),
                        }

            # 3. é›†æˆåˆ°æ¯æ—¥æ–‡ä»¶
            logger.info("ğŸ”„ å¼€å§‹é›†æˆæ–°å¸ç§æ•°æ®åˆ°æ¯æ—¥æ–‡ä»¶...")

            for coin in new_coins:
                download_result = results["download_results"][coin]
                if download_result["success"]:
                    try:
                        inserted_count, total_attempts = (
                            self.integrate_new_coin_into_daily_files(coin)
                        )
                        results["integration_results"][coin] = {
                            "success": inserted_count > 0,
                            "inserted_days": inserted_count,
                            "total_attempts": total_attempts,
                            "success_rate": (
                                (inserted_count / total_attempts * 100)
                                if total_attempts > 0
                                else 0
                            ),
                            "error": None,
                        }
                    except Exception as e:
                        logger.error(f"é›†æˆ {coin} æ—¶å‡ºé”™: {e}")
                        results["integration_results"][coin] = {
                            "success": False,
                            "inserted_days": 0,
                            "total_attempts": 0,
                            "success_rate": 0,
                            "error": str(e),
                        }
                else:
                    results["integration_results"][coin] = {
                        "success": False,
                        "inserted_days": 0,
                        "total_attempts": 0,
                        "success_rate": 0,
                        "error": "ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡é›†æˆ",
                    }

            # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            successful_downloads = sum(
                1 for r in results["download_results"].values() if r["success"]
            )
            successful_integrations = sum(
                1 for r in results["integration_results"].values() if r["success"]
            )
            total_insertions = sum(
                r["inserted_days"] for r in results["integration_results"].values()
            )

            results["summary"].update(
                {
                    "end_time": end_time.isoformat(),
                    "duration_seconds": duration,
                    "new_coins_count": len(new_coins),
                    "successful_downloads": successful_downloads,
                    "successful_integrations": successful_integrations,
                    "total_insertions": total_insertions,
                    "status": "completed",
                }
            )

            logger.info("=" * 60)
            logger.info("ğŸ“Š å¢é‡æ›´æ–°å®Œæˆ")
            logger.info(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {duration:.1f} ç§’")
            logger.info(f"ğŸ†• æ–°å¸ç§æ•°é‡: {len(new_coins)}")
            logger.info(f"ğŸ“¥ æˆåŠŸä¸‹è½½: {successful_downloads}/{len(new_coins)}")
            logger.info(f"ğŸ”„ æˆåŠŸé›†æˆ: {successful_integrations}/{len(new_coins)}")
            logger.info(f"ğŸ“Š æ€»æ’å…¥æ¬¡æ•°: {total_insertions}")
            logger.info("=" * 60)

            return results

        except Exception as e:
            logger.error(f"å¢é‡æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            results["summary"]["status"] = "error"
            results["summary"]["error"] = str(e)
            return results


def create_incremental_updater(
    coins_dir: str = "data/coins",
    daily_dir: str = "data/daily/daily_files",
    backup_enabled: bool = True,
) -> IncrementalDailyUpdater:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºå¢é‡æ›´æ–°å™¨å®ä¾‹"""
    return IncrementalDailyUpdater(coins_dir, daily_dir, backup_enabled)
