"""
ä»·æ ¼æ•°æ®æ›´æ–°å™¨

æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼Œæä¾›æ™ºèƒ½çš„ä»·æ ¼æ•°æ®æ›´æ–°ç­–ç•¥ã€‚

è®¾è®¡å“²å­¦ï¼š
1. ç®€å•èƒœäºå¤æ‚ - æ¯ä¸ªæ–¹æ³•èŒè´£å•ä¸€
2. ä¿¡ä»»æƒå¨æ•°æ®æº - åŸºäºCoinGeckoå®˜æ–¹åˆ†ç±»
3. ç”¨æˆ·å¯¼å‘è®¾è®¡ - ç¡®ä¿ç”¨æˆ·éœ€æ±‚å¾—åˆ°æ»¡è¶³

æ ¸å¿ƒç­–ç•¥ï¼š
1. æŒ‰å¸‚å€¼é¡ºåºè·å–å¸ç§
2. åŸºäºCoinGecko categoryç®€å•åˆ†ç±»ï¼šéåŒ…è£…å¸ä¸”éç¨³å®šå¸ = åŸç”Ÿå¸
3. æŒ‰é¡ºåºæ›´æ–°ï¼Œç¡®ä¿åŸç”Ÿå¸è¾¾åˆ°ç›®æ ‡æ•°é‡
4. åŒæ—¶æ›´æ–°é‡åˆ°çš„éåŸç”Ÿå¸ï¼ˆä¸ºæœªæ¥ç ”ç©¶å‡†å¤‡ï¼‰
"""

import logging
import math
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

from tqdm import tqdm

from ..api.coingecko import CoinGeckoAPI
from ..classification.stablecoin_checker import StablecoinChecker
from ..classification.wrapped_coin_checker import WrappedCoinChecker
from ..downloaders.batch_downloader import create_batch_downloader

# APIé™æµé…ç½®
RATE_LIMIT_CONFIG = {
    "delay_seconds": 0.13,
    "calls_per_minute": 461.5,
}

logger = logging.getLogger(__name__)


class CoinClassifier:
    """å¸ç§åˆ†ç±»å™¨ - èŒè´£å•ä¸€ï¼šåŸºäºCoinGeckoåˆ†ç±»å¸ç§"""

    def __init__(self):
        self.stablecoin_checker = StablecoinChecker()
        self.wrapped_checker = WrappedCoinChecker()

    def classify_coin(self, coin_id: str) -> str:
        """
        åˆ†ç±»å•ä¸ªå¸ç§

        Args:
            coin_id: å¸ç§ID

        Returns:
            'stable' | 'wrapped' | 'native'
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¨³å®šå¸
        stable_result = self.stablecoin_checker.is_stablecoin(coin_id)
        if isinstance(stable_result, dict):
            is_stable = stable_result.get("is_stablecoin", False)
        else:
            is_stable = stable_result

        if is_stable:
            return "stable"

        # æ£€æŸ¥æ˜¯å¦ä¸ºåŒ…è£…å¸
        wrapped_result = self.wrapped_checker.is_wrapped_coin(coin_id)
        if isinstance(wrapped_result, dict):
            is_wrapped = wrapped_result.get("is_wrapped_coin", False)
        else:
            is_wrapped = wrapped_result

        if is_wrapped:
            return "wrapped"

        # æ—¢ä¸æ˜¯ç¨³å®šå¸ä¹Ÿä¸æ˜¯åŒ…è£…å¸ï¼Œå°±æ˜¯åŸç”Ÿå¸
        return "native"


class MarketDataFetcher:
    """å¸‚åœºæ•°æ®è·å–å™¨ - èŒè´£å•ä¸€ï¼šè·å–å¸‚å€¼æ’åæ•°æ®"""

    def __init__(self, api: CoinGeckoAPI):
        self.api = api

    def get_top_coins(self, n: int) -> List[Dict]:
        """
        è·å–å¸‚å€¼å‰Nåå¸ç§

        Args:
            n: ç›®æ ‡å¸ç§æ•°é‡

        Returns:
            å¸ç§åˆ—è¡¨ï¼ŒæŒ‰å¸‚å€¼æ’åº
        """
        logger.info(f"ğŸ” è·å–å¸‚å€¼å‰ {n} ååŠ å¯†è´§å¸")

        coins = []
        pages = math.ceil(n / 250)  # æ¯é¡µæœ€å¤š250ä¸ª

        with tqdm(
            total=pages,
            desc="è·å–å¸‚å€¼æ’å",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
            leave=False,
        ) as pbar:
            for page in range(1, pages + 1):
                try:
                    # è®¡ç®—è¿™ä¸€é¡µåº”è¯¥è·å–å¤šå°‘ä¸ªå¸ç§
                    per_page = min(250, n - len(coins))
                    market_data = self.api.get_coins_markets(
                        vs_currency="usd",
                        order="market_cap_desc",
                        per_page=per_page,
                        page=page,
                        sparkline=False,
                    )

                    if not market_data:
                        logger.warning(f"ç¬¬ {page} é¡µæœªè·å–åˆ°æ•°æ®ï¼Œåœæ­¢è·å–")
                        break

                    for coin in market_data:
                        if len(coins) >= n:
                            break
                        coins.append(
                            {
                                "id": coin["id"],
                                "symbol": coin["symbol"],
                                "name": coin["name"],
                                "market_cap_rank": coin.get("market_cap_rank", 0),
                            }
                        )

                    pbar.set_postfix({"å·²è·å–": len(coins), "ç›®æ ‡": n, "å½“å‰é¡µ": page})
                    pbar.update(1)

                    if len(coins) >= n:
                        break

                except Exception as e:
                    logger.error(f"è·å–ç¬¬ {page} é¡µæ•°æ®æ—¶å‡ºé”™: {e}")
                    break

                # APIé™æµå»¶è¿Ÿ
                time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])

        logger.info(f"âœ… æˆåŠŸè·å– {len(coins)} ä¸ªå¸ç§çš„å¸‚å€¼æ’å")
        return coins[:n]


class PriceDataUpdater:
    """ä»·æ ¼æ•°æ®æ›´æ–°å™¨ - ä¸»è¦é€»è¾‘åè°ƒè€…"""

    def __init__(self):
        self.api = CoinGeckoAPI()
        self.downloader = create_batch_downloader()
        self.classifier = CoinClassifier()
        self.market_fetcher = MarketDataFetcher(self.api)

        # ç›®å½•è®¾ç½®
        self.coins_dir = Path("data/coins")
        self.metadata_dir = Path("data/metadata")

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "start_time": None,
            "end_time": None,
            "total_processed": 0,
            "native_updated": 0,
            "stable_updated": 0,
            "wrapped_updated": 0,
            "failed_updates": 0,
            "new_coins": 0,
            "api_calls": 0,
        }

        self.errors = []

    def needs_update(self, coin_id: str) -> Tuple[bool, Optional[str]]:
        """æ£€æŸ¥å¸ç§æ˜¯å¦éœ€è¦æ›´æ–°"""
        csv_file = self.coins_dir / f"{coin_id}.csv"

        if not csv_file.exists():
            return True, None

        try:
            # è¯»å–æœ€åä¸€è¡Œè·å–æœ€æ–°æ—¶é—´æˆ³
            with open(csv_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
                if len(lines) <= 1:  # åªæœ‰è¡¨å¤´
                    return True, None

                last_line = lines[-1].strip()
                if not last_line:
                    return True, None

                # è·å–æ—¶é—´æˆ³å¹¶è½¬æ¢ä¸ºæ—¥æœŸ
                timestamp_str = last_line.split(",")[0]
                try:
                    timestamp = int(float(timestamp_str))
                    # è½¬æ¢ä¸ºUTCæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
                    last_date = datetime.fromtimestamp(
                        timestamp / 1000, tz=timezone.utc
                    )
                    today_utc = datetime.now(tz=timezone.utc)

                    # æ¯”è¾ƒæ—¥æœŸéƒ¨åˆ†
                    last_date_str = last_date.strftime("%Y-%m-%d")
                    today_str = today_utc.strftime("%Y-%m-%d")

                    if last_date_str < today_str:
                        logger.debug(
                            f"{coin_id}: æ•°æ®è¿‡æœŸ (æœ€æ–°: {last_date_str}, ä»Šå¤©: {today_str})"
                        )
                        return True, last_date_str
                    else:
                        logger.debug(
                            f"{coin_id}: æ•°æ®æœ€æ–° (æœ€æ–°: {last_date_str}, ä»Šå¤©: {today_str})"
                        )
                        return False, last_date_str
                except (ValueError, TypeError) as e:
                    logger.warning(f"{coin_id}: æ—¶é—´æˆ³æ ¼å¼é”™è¯¯ {timestamp_str}: {e}")
                    return True, None

        except Exception as e:
            logger.error(f"æ£€æŸ¥ {coin_id} æ›´æ–°çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return True, None

    def download_coin_data(
        self, coin_id: str, is_new_coin: bool, from_date: Optional[str]
    ) -> bool:
        """ä¸‹è½½å¸ç§æ•°æ®"""
        try:
            if is_new_coin:
                logger.info(f"ğŸ“¥ æ–°å¸ç§ {coin_id}ï¼Œä¸‹è½½å®Œæ•´å†å²æ•°æ®...")
                success = self.downloader.download_coin_data(coin_id, days="max")
            else:
                days_to_update = (
                    self._calculate_days_since(from_date) if from_date else 1
                )
                logger.info(
                    f"ğŸ“¥ å¢é‡æ›´æ–° {coin_id}ï¼Œä» {from_date} å¼€å§‹ï¼Œå…± {days_to_update} å¤©..."
                )
                success = self.downloader.download_coin_data(
                    coin_id, days=str(days_to_update)
                )

            if success:
                logger.info(f"âœ… {coin_id} æ•°æ®ä¸‹è½½æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ {coin_id} æ•°æ®ä¸‹è½½å¤±è´¥")
                return False

        except Exception as e:
            logger.error(f"ä¸‹è½½ {coin_id} æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def _calculate_days_since(self, date_str: str) -> int:
        """è®¡ç®—ä»æŒ‡å®šæ—¥æœŸåˆ°ä»Šå¤©çš„å¤©æ•°"""
        try:
            from datetime import date

            target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
            today = datetime.now(tz=timezone.utc).date()
            days_diff = (today - target_date).days + 1  # +1 ç¡®ä¿åŒ…å«ä»Šå¤©
            return max(1, days_diff)  # è‡³å°‘è¿”å›1å¤©
        except Exception as e:
            logger.warning(f"è®¡ç®—æ—¥æœŸå·®å¼‚å¤±è´¥: {e}, é»˜è®¤è¿”å›1å¤©")
            return 1

    def get_existing_coin_ids(self) -> Set[str]:
        """è·å–å·²å­˜åœ¨çš„å¸ç§ID"""
        existing_ids = set()
        if self.coins_dir.exists():
            for csv_file in self.coins_dir.glob("*.csv"):
                coin_id = csv_file.stem
                existing_ids.add(coin_id)
        return existing_ids

    def update_with_smart_strategy(
        self, target_native_coins: int = 510, max_search_range: int = 1000
    ):
        """
        æ™ºèƒ½æ›´æ–°ç­–ç•¥

        Args:
            target_native_coins: ç›®æ ‡åŸç”Ÿå¸ç§æ•°é‡
            max_search_range: æœ€å¤§æœç´¢èŒƒå›´
        """
        logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½é‡ä»·æ•°æ®æ›´æ–°")
        logger.info(f"ğŸ“‹ ç›®æ ‡: ç¡®ä¿è‡³å°‘ {target_native_coins} ä¸ªåŸç”Ÿå¸ç§æ•°æ®æœ€æ–°")
        logger.info(f"ğŸ” æœ€å¤§æœç´¢èŒƒå›´: {max_search_range} ä¸ªå¸ç§")
        logger.info("=" * 60)

        self.stats["start_time"] = datetime.now()

        try:
            # 1. è·å–ç°æœ‰å¸ç§ID
            existing_ids = self.get_existing_coin_ids()
            logger.info(f"ğŸ“‹ ç°æœ‰å¸ç§æ•°é‡: {len(existing_ids)}")

            # 2. æŒ‰å¸‚å€¼é¡ºåºè·å–å¸ç§å¹¶é€ä¸ªå¤„ç†
            native_coins_updated = 0
            search_range = min(
                max_search_range, target_native_coins * 2
            )  # å¼€å§‹æœç´¢èŒƒå›´

            while (
                native_coins_updated < target_native_coins
                and search_range <= max_search_range
            ):
                logger.info(f"ğŸ” æœç´¢å¸‚å€¼å‰ {search_range} åå¸ç§...")

                # è·å–å¸‚å€¼æ’åæ•°æ®
                all_coins = self.market_fetcher.get_top_coins(search_range)

                # æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªå¸ç§
                with tqdm(
                    total=len(all_coins),
                    desc="å¤„ç†å¸ç§æ•°æ®",
                    bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]",
                    ncols=120,
                    leave=False,
                ) as pbar:
                    for coin_info in all_coins:
                        coin_id = coin_info["id"]
                        coin_symbol = coin_info["symbol"].upper()

                        try:
                            # åˆ†ç±»å¸ç§
                            coin_type = self.classifier.classify_coin(coin_id)

                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                            is_new_coin = coin_id not in existing_ids
                            needs_update, last_date = self.needs_update(coin_id)

                            if needs_update:
                                # ä¸‹è½½æ•°æ®
                                success = self.download_coin_data(
                                    coin_id, is_new_coin, last_date
                                )

                                if success:
                                    # æ›´æ–°ç»Ÿè®¡
                                    if coin_type == "native":
                                        native_coins_updated += 1
                                        self.stats["native_updated"] += 1
                                    elif coin_type == "stable":
                                        self.stats["stable_updated"] += 1
                                    elif coin_type == "wrapped":
                                        self.stats["wrapped_updated"] += 1

                                    if is_new_coin:
                                        self.stats["new_coins"] += 1
                                        existing_ids.add(coin_id)

                                    self.stats["api_calls"] += 1

                                    # APIé™æµå»¶è¿Ÿ
                                    time.sleep(RATE_LIMIT_CONFIG["delay_seconds"])
                                else:
                                    self.stats["failed_updates"] += 1
                                    self.errors.append(f"{coin_id}: ä¸‹è½½å¤±è´¥")
                            else:
                                # æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œä½†å¦‚æœæ˜¯åŸç”Ÿå¸ä»è®¡å…¥ç»Ÿè®¡
                                if coin_type == "native":
                                    native_coins_updated += 1
                                    self.stats["native_updated"] += 1

                            self.stats["total_processed"] += 1

                            # æ›´æ–°è¿›åº¦æ¡
                            pbar.set_postfix(
                                {
                                    "åŸç”Ÿå¸": native_coins_updated,
                                    "ç›®æ ‡": target_native_coins,
                                    "ç±»å‹": coin_type,
                                    "å½“å‰": coin_symbol[:10],
                                }
                            )
                            pbar.update(1)

                            # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡ï¼Œæå‰ç»“æŸ
                            if native_coins_updated >= target_native_coins:
                                logger.info(
                                    f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡ï¼æˆåŠŸå¤„ç† {native_coins_updated} ä¸ªåŸç”Ÿå¸ç§"
                                )
                                break

                        except Exception as e:
                            logger.error(f"å¤„ç† {coin_id} æ—¶å‡ºé”™: {e}")
                            self.errors.append(f"{coin_id}: {str(e)}")
                            self.stats["failed_updates"] += 1
                            pbar.update(1)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰©å¤§æœç´¢èŒƒå›´
                if native_coins_updated < target_native_coins:
                    if search_range >= max_search_range:
                        logger.warning(
                            f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§æœç´¢èŒƒå›´ {max_search_range}ï¼Œä½†åªæ‰¾åˆ° {native_coins_updated} ä¸ªåŸç”Ÿå¸ç§"
                        )
                        break
                    else:
                        search_range = min(search_range + 200, max_search_range)
                        logger.info(f"ğŸ”„ æ‰©å¤§æœç´¢èŒƒå›´åˆ° {search_range}...")
                else:
                    break

            # æ›´æ–°å…ƒæ•°æ®
            logger.info("ğŸ’° æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®...")
            self.update_metadata()

            # éªŒè¯ç»“æœ
            if native_coins_updated >= target_native_coins:
                logger.info(
                    f"âœ… æˆåŠŸè¾¾æˆç›®æ ‡ï¼å¤„ç†äº† {native_coins_updated} ä¸ªåŸç”Ÿå¸ç§"
                )
            else:
                logger.warning(
                    f"âš ï¸ æœªå®Œå…¨è¾¾æˆç›®æ ‡ï¼Œåªå¤„ç†äº† {native_coins_updated}/{target_native_coins} ä¸ªåŸç”Ÿå¸ç§"
                )

        except Exception as e:
            logger.error(f"æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            self.errors.append(f"æ›´æ–°å¼‚å¸¸: {str(e)}")

        finally:
            self.stats["end_time"] = datetime.now()
            duration = self.stats["end_time"] - self.stats["start_time"]

            # ç”ŸæˆæŠ¥å‘Š
            self.generate_final_report(duration)

    def update_metadata(self):
        """æ›´æ–°ç¨³å®šå¸å’ŒåŒ…è£…å¸å…ƒæ•°æ®"""
        try:
            # æ›´æ–°ç¨³å®šå¸å…ƒæ•°æ®
            stablecoin_checker = StablecoinChecker()
            # å¯¼å‡ºç¨³å®šå¸åˆ—è¡¨ (åŸºäºç°æœ‰æ–¹æ³•)
            stablecoins = stablecoin_checker.get_all_stablecoins()
            stable_file = self.metadata_dir / "stablecoins.csv"

            with open(stable_file, "w", encoding="utf-8") as f:
                f.write("coin_id,symbol,name\n")
                for coin_info in stablecoins:
                    f.write(
                        f"{coin_info.get('id', '')},{coin_info.get('symbol', '')},{coin_info.get('name', '')}\n"
                    )

            print(f"âœ… ç¨³å®šå¸åˆ—è¡¨å·²å¯¼å‡ºåˆ°: {stable_file}")
            print(f"   å…±å¯¼å‡º {len(stablecoins)} ä¸ªç¨³å®šå¸")

            # æ›´æ–°åŒ…è£…å¸å…ƒæ•°æ®
            wrapped_checker = WrappedCoinChecker()
            # å¯¼å‡ºåŒ…è£…å¸åˆ—è¡¨ (åŸºäºç°æœ‰æ–¹æ³•)
            wrapped_coins = wrapped_checker.get_all_wrapped_coins()
            wrapped_file = self.metadata_dir / "wrapped_coins.csv"

            with open(wrapped_file, "w", encoding="utf-8") as f:
                f.write("coin_id,symbol,name\n")
                for coin_info in wrapped_coins:
                    f.write(
                        f"{coin_info.get('id', '')},{coin_info.get('symbol', '')},{coin_info.get('name', '')}\n"
                    )

            print(f"âœ… åŒ…è£…å¸åˆ—è¡¨å·²å¯¼å‡ºåˆ°: {wrapped_file}")
            print(f"   å…±å¯¼å‡º {len(wrapped_coins)} ä¸ªåŒ…è£…å¸")

            logger.info("âœ… å…ƒæ•°æ®æ›´æ–°å®Œæˆ")
        except Exception as e:
            logger.error(f"æ›´æ–°å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            self.errors.append(f"å…ƒæ•°æ®æ›´æ–°é”™è¯¯: {str(e)}")

    def generate_final_report(self, duration):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report = f"""
ğŸ” æ™ºèƒ½é‡ä»·æ•°æ®æ›´æ–°æŠ¥å‘Š
============================================================
ğŸ“Š å¤„ç†ç»Ÿè®¡:
   - æ€»å¤„ç†å¸ç§æ•°: {self.stats['total_processed']}
   - åŸç”Ÿå¸æ›´æ–°æ•°: {self.stats['native_updated']}
   - ç¨³å®šå¸æ›´æ–°æ•°: {self.stats['stable_updated']}
   - åŒ…è£…å¸æ›´æ–°æ•°: {self.stats['wrapped_updated']}
   - æ–°å¸ç§æ•°: {self.stats['new_coins']}
   - å¤±è´¥æ›´æ–°æ•°: {self.stats['failed_updates']}

âš¡ æ€§èƒ½ç»Ÿè®¡:
   - APIè°ƒç”¨æ¬¡æ•°: {self.stats['api_calls']}
   - æ€»è€—æ—¶: {duration}

ğŸ• æ—¶é—´ä¿¡æ¯:
   - å¼€å§‹æ—¶é—´: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
   - ç»“æŸæ—¶é—´: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}

{'âœ… æ— é”™è¯¯' if not self.errors else f'âŒ é”™è¯¯åˆ—è¡¨:'}
{chr(10).join(f'   - {error}' for error in self.errors[:10]) if self.errors else ''}
"""

        logger.info(report)

        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = (
            Path("logs")
            / f"smart_update_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        )
        report_file.write_text(report, encoding="utf-8")

        logger.info(f"ğŸ“‹ æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        logger.info("ğŸ‰ æ™ºèƒ½é‡ä»·æ•°æ®æ›´æ–°æµç¨‹å®Œæˆï¼")
