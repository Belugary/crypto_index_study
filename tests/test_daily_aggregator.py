#!/usr/bin/env python3
"""
DailyDataAggregator æµ‹è¯•æ¨¡å—

æµ‹è¯•è¦†ç›–ï¼š
1. æ•°æ®åŠ è½½å’Œèšåˆ
2. æ¯æ—¥æ•°æ®è®¡ç®—
3. å¹¶å‘å¤„ç†
4. æ•°æ®è¦†ç›–åˆ†æ
5. æ–‡ä»¶é‡æ’åº
6. é”™è¯¯å¤„ç†
7. ç¼“å­˜æœºåˆ¶å’Œå‚æ•°è¿‡æ»¤ (result_include_all ä¿®å¤æµ‹è¯•)
"""

import os
import sys
import unittest
import tempfile
import shutil
from datetime import date, datetime, timedelta
from pathlib import Path
from unittest.mock import patch, MagicMock
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.downloaders.daily_aggregator import DailyDataAggregator


class TestDailyDataAggregator(unittest.TestCase):
    """DailyDataAggregator æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
        self.data_dir = Path(self.temp_dir) / "coins"
        self.output_dir = Path(self.temp_dir) / "daily"
        self.data_dir.mkdir(parents=True)
        self.output_dir.mkdir(parents=True)

        print(f"\n--- æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ– ---")
        print(f"ä¸´æ—¶ç›®å½•: {self.temp_dir}")

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self._create_test_coin_data()

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.temp_dir)
        print("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")

    def _create_test_coin_data(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„å¸ç§æ•°æ®"""
        # åˆ›å»º 3 ä¸ªå¸ç§çš„å†å²æ•°æ®
        coins_data = {
            "bitcoin": {
                "dates": ["2024-01-01", "2024-01-02", "2024-01-03"],
                "prices": [40000, 42000, 41000],
                "volumes": [1e9, 1.1e9, 1.05e9],
                "market_caps": [8e11, 8.4e11, 8.2e11],
            },
            "ethereum": {
                "dates": ["2024-01-01", "2024-01-02", "2024-01-03"],
                "prices": [2500, 2700, 2600],
                "volumes": [5e8, 6e8, 5.5e8],
                "market_caps": [3e11, 3.24e11, 3.12e11],
            },
            "solana": {
                "dates": ["2024-01-02", "2024-01-03"],  # å¼€å§‹æ—¥æœŸæ™šä¸€å¤©
                "prices": [100, 110],
                "volumes": [2e8, 2.2e8],
                "market_caps": [4e10, 4.4e10],
            },
        }

        for coin_id, data in coins_data.items():
            df_data = []
            for i, date_str in enumerate(data["dates"]):
                timestamp = pd.Timestamp(date_str).timestamp() * 1000
                df_data.append(
                    {
                        "timestamp": timestamp,
                        "price": data["prices"][i],
                        "volume": data["volumes"][i],
                        "market_cap": data["market_caps"][i],
                    }
                )

            df = pd.DataFrame(df_data)
            coin_file = self.data_dir / f"{coin_id}.csv"
            df.to_csv(coin_file, index=False)

        print(f"âœ… åˆ›å»ºäº† {len(coins_data)} ä¸ªæµ‹è¯•å¸ç§çš„æ•°æ®")

    def test_01_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        print("\n--- æµ‹è¯• 1: DailyDataAggregator åˆå§‹åŒ– ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )

        self.assertEqual(aggregator.data_dir, self.data_dir)
        self.assertEqual(aggregator.output_dir, self.output_dir)
        self.assertEqual(len(aggregator.coin_data), 0)  # åˆå§‹åŒ–æ—¶ä¸ºç©º
        self.assertEqual(len(aggregator.daily_cache), 0)
        
        # æµ‹è¯•æ–°å¢å±æ€§
        self.assertTrue(hasattr(aggregator, 'result_include_all'))
        self.assertEqual(aggregator.result_include_all, False)  # é»˜è®¤å€¼
        self.assertTrue(hasattr(aggregator, 'project_root'))
        self.assertTrue(hasattr(aggregator, 'log_folder'))

        print("âœ… åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_01b_result_include_all_parameter(self):
        """æµ‹è¯• result_include_all å‚æ•°åŠŸèƒ½"""
        print("\n--- æµ‹è¯• 1b: result_include_all å‚æ•° ---")

        # æµ‹è¯•é»˜è®¤å€¼
        aggregator_default = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        self.assertEqual(aggregator_default.result_include_all, False)
        
        # æµ‹è¯•æ˜¾å¼è®¾ç½®ä¸º True
        aggregator_true = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir), result_include_all=True
        )
        self.assertEqual(aggregator_true.result_include_all, True)
        
        # æµ‹è¯•æ˜¾å¼è®¾ç½®ä¸º False
        aggregator_false = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir), result_include_all=False
        )
        self.assertEqual(aggregator_false.result_include_all, False)
        
        print("âœ… result_include_all å‚æ•°æµ‹è¯•é€šè¿‡")

    def test_02_load_coin_data(self):
        """æµ‹è¯•å¸ç§æ•°æ®åŠ è½½"""
        print("\n--- æµ‹è¯• 2: å¸ç§æ•°æ®åŠ è½½ ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )

        # åŠ è½½æ•°æ®
        aggregator.load_coin_data()
        aggregator._calculate_date_range()  # æ‰‹åŠ¨è°ƒç”¨æ—¥æœŸèŒƒå›´è®¡ç®—

        # éªŒè¯åŠ è½½ç»“æœ
        self.assertEqual(len(aggregator.coin_data), 3)
        self.assertIn("bitcoin", aggregator.coin_data)
        self.assertIn("ethereum", aggregator.coin_data)
        self.assertIn("solana", aggregator.coin_data)

        # éªŒè¯æ•°æ®æ ¼å¼
        btc_df = aggregator.coin_data["bitcoin"]
        self.assertIn("date", btc_df.columns)
        self.assertIn("coin_id", btc_df.columns)
        self.assertEqual(len(btc_df), 3)
        self.assertEqual(btc_df["coin_id"].iloc[0], "bitcoin")

        # éªŒè¯æ—¥æœŸèŒƒå›´è®¡ç®—
        self.assertIsNotNone(aggregator.min_date)
        self.assertIsNotNone(aggregator.max_date)
        if aggregator.min_date and aggregator.max_date:
            self.assertEqual(aggregator.min_date.date(), date(2024, 1, 1))
            self.assertEqual(aggregator.max_date.date(), date(2024, 1, 3))

        print(f"âœ… æˆåŠŸåŠ è½½ {len(aggregator.coin_data)} ä¸ªå¸ç§")
        print(f"   æ—¥æœŸèŒƒå›´: {aggregator.min_date} ~ {aggregator.max_date}")

    def test_03_get_daily_data(self):
        """æµ‹è¯•å•æ—¥æ•°æ®è·å–"""
        print("\n--- æµ‹è¯• 3: å•æ—¥æ•°æ®è·å– ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()

        # è·å– 2024-01-01 çš„æ•°æ®
        daily_df = aggregator.get_daily_data("2024-01-01")

        # éªŒè¯ç»“æœ
        self.assertFalse(daily_df.empty)
        self.assertEqual(len(daily_df), 2)  # bitcoin å’Œ ethereum
        self.assertIn("bitcoin", daily_df["coin_id"].values)
        self.assertIn("ethereum", daily_df["coin_id"].values)
        self.assertNotIn("solana", daily_df["coin_id"].values)  # solana ä» 01-02 å¼€å§‹

        # éªŒè¯æŒ‰å¸‚å€¼æ’åº
        market_caps = daily_df["market_cap"].tolist()
        self.assertEqual(market_caps, sorted(market_caps, reverse=True))

        # éªŒè¯ rank å­—æ®µ
        self.assertIn("rank", daily_df.columns)
        self.assertEqual(daily_df["rank"].tolist(), [1, 2])

        print(f"âœ… 2024-01-01 æ•°æ®è·å–æˆåŠŸ: {len(daily_df)} ä¸ªå¸ç§")

        # è·å– 2024-01-02 çš„æ•°æ®
        daily_df_2 = aggregator.get_daily_data("2024-01-02")
        self.assertEqual(len(daily_df_2), 3)  # æ‰€æœ‰å¸ç§éƒ½æœ‰æ•°æ®

        print(f"âœ… 2024-01-02 æ•°æ®è·å–æˆåŠŸ: {len(daily_df_2)} ä¸ªå¸ç§")

    def test_04_data_coverage_analysis(self):
        """æµ‹è¯•æ•°æ®è¦†ç›–åˆ†æ"""
        print("\n--- æµ‹è¯• 4: æ•°æ®è¦†ç›–åˆ†æ ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()
        aggregator._calculate_date_range()  # æ‰‹åŠ¨è°ƒç”¨æ—¥æœŸèŒƒå›´è®¡ç®—

        analysis = aggregator.get_data_coverage_analysis()

        # éªŒè¯åˆ†æç»“æœ
        self.assertEqual(analysis["total_coins"], 3)
        self.assertIn("2024-01-01", analysis["date_range"]["start"])  # å…è®¸åŒ…å«æ—¶é—´éƒ¨åˆ†
        self.assertIn("2024-01-03", analysis["date_range"]["end"])
        self.assertEqual(analysis["date_range"]["total_days"], 3)

        # éªŒè¯å¸ç§è¯¦æƒ…
        coin_details = analysis["coin_details"]
        self.assertEqual(len(coin_details), 3)

        # æ‰¾åˆ°æ¯ä¸ªå¸ç§çš„åˆ†æ
        btc_detail = next(c for c in coin_details if c["coin_id"] == "bitcoin")
        eth_detail = next(c for c in coin_details if c["coin_id"] == "ethereum")
        sol_detail = next(c for c in coin_details if c["coin_id"] == "solana")

        self.assertEqual(btc_detail["data_points"], 3)
        self.assertEqual(eth_detail["data_points"], 3)
        self.assertEqual(sol_detail["data_points"], 2)

        print(f"âœ… æ•°æ®è¦†ç›–åˆ†æå®Œæˆ")
        print(f"   æ€»å¸ç§: {analysis['total_coins']}")
        print(f"   æ—¥æœŸèŒƒå›´: {analysis['date_range']['total_days']} å¤©")

    def test_05_find_bitcoin_start_date(self):
        """æµ‹è¯•æ¯”ç‰¹å¸å¼€å§‹æ—¥æœŸæŸ¥æ‰¾"""
        print("\n--- æµ‹è¯• 5: æ¯”ç‰¹å¸å¼€å§‹æ—¥æœŸæŸ¥æ‰¾ ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()

        btc_start = aggregator.find_bitcoin_start_date()

        self.assertEqual(btc_start, "2024-01-01")

        print(f"âœ… æ¯”ç‰¹å¸å¼€å§‹æ—¥æœŸ: {btc_start}")

    def test_06_build_daily_tables_basic(self):
        """æµ‹è¯•åŸºç¡€æ¯æ—¥è¡¨æ ¼æ„å»º"""
        print("\n--- æµ‹è¯• 6: åŸºç¡€æ¯æ—¥è¡¨æ ¼æ„å»º ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()

        # æ„å»ºæ¯æ—¥è¡¨æ ¼ï¼ˆåªæ„å»º2å¤©ï¼Œé¿å…è¿‡é•¿æµ‹è¯•ï¼‰
        aggregator.build_daily_tables(force_recalculate=True)

        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        daily_files_dir = self.output_dir / "daily_files" / "2024" / "01"
        self.assertTrue(daily_files_dir.exists())

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        expected_files = ["2024-01-01.csv", "2024-01-02.csv", "2024-01-03.csv"]
        for file_name in expected_files:
            file_path = daily_files_dir / file_name
            self.assertTrue(file_path.exists(), f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            # éªŒè¯æ–‡ä»¶å†…å®¹
            df = pd.read_csv(file_path)
            self.assertFalse(df.empty)
            self.assertIn("coin_id", df.columns)
            self.assertIn("rank", df.columns)
            self.assertIn("market_cap", df.columns)

        # éªŒè¯åˆå¹¶æ–‡ä»¶
        merged_file = self.output_dir / "merged_daily_data.csv"
        self.assertTrue(merged_file.exists())

        merged_df = pd.read_csv(merged_file)
        self.assertFalse(merged_df.empty)
        self.assertGreater(len(merged_df), 0)

        print(f"âœ… æ¯æ—¥è¡¨æ ¼æ„å»ºå®Œæˆ")
        print(f"   ç”Ÿæˆäº† {len(expected_files)} ä¸ªæ¯æ—¥æ–‡ä»¶")

    def test_07_load_daily_data_from_files(self):
        """æµ‹è¯•ä»æ–‡ä»¶åŠ è½½æ¯æ—¥æ•°æ®"""
        print("\n--- æµ‹è¯• 7: ä»æ–‡ä»¶åŠ è½½æ¯æ—¥æ•°æ® ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )

        # å…ˆæ„å»ºä¸€äº›æ¯æ—¥æ–‡ä»¶
        aggregator.load_coin_data()
        aggregator.get_daily_data("2024-01-01")  # è¿™ä¼šç”Ÿæˆæ–‡ä»¶

        # æ¸…ç©ºç¼“å­˜
        aggregator.daily_cache.clear()

        # ä»æ–‡ä»¶åŠ è½½
        aggregator.load_daily_data_from_files()

        # éªŒè¯åŠ è½½ç»“æœ
        self.assertGreater(len(aggregator.daily_cache), 0)
        self.assertIn("2024-01-01", aggregator.daily_cache)

        print(f"âœ… ä»æ–‡ä»¶åŠ è½½äº† {len(aggregator.daily_cache)} å¤©çš„æ•°æ®")

    def test_08_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\n--- æµ‹è¯• 8: é”™è¯¯å¤„ç† ---")

        # æµ‹è¯•ç©ºç›®å½•
        empty_dir = Path(self.temp_dir) / "empty"
        empty_dir.mkdir()

        aggregator = DailyDataAggregator(
            data_dir=str(empty_dir), output_dir=str(self.output_dir)
        )

        aggregator.load_coin_data()
        self.assertEqual(len(aggregator.coin_data), 0)

        # æµ‹è¯•æ— æ•ˆæ—¥æœŸ
        daily_df = aggregator.get_daily_data("invalid-date")
        self.assertTrue(daily_df.empty)

        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_09_date_range_methods(self):
        """æµ‹è¯•æ—¥æœŸèŒƒå›´ç›¸å…³æ–¹æ³•"""
        print("\n--- æµ‹è¯• 9: æ—¥æœŸèŒƒå›´ç›¸å…³æ–¹æ³• ---")

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()
        aggregator._calculate_date_range()  # æ‰‹åŠ¨è°ƒç”¨æ—¥æœŸèŒƒå›´è®¡ç®—

        # æµ‹è¯•æ—¥æœŸèŒƒå›´æ‘˜è¦
        summary = aggregator.get_date_range_summary()

        self.assertIn("start_date", summary)
        self.assertIn("end_date", summary)
        self.assertIn("coverage", summary)
        # å…è®¸æ—¥æœŸæ ¼å¼æœ‰æ‰€ä¸åŒï¼Œåªè¦åŒ…å«æ­£ç¡®çš„æ—¥æœŸå³å¯
        if summary["start_date"]:
            self.assertIn("2024-01-01", str(summary["start_date"]))
        if summary["end_date"]:
            self.assertIn("2024-01-03", str(summary["end_date"]))

        print(f"âœ… æ—¥æœŸèŒƒå›´æ‘˜è¦: {summary['start_date']} ~ {summary['end_date']}")

    @patch("multiprocessing.cpu_count")
    def test_10_concurrent_processing(self, mock_cpu_count):
        """æµ‹è¯•å¹¶å‘å¤„ç†ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("\n--- æµ‹è¯• 10: å¹¶å‘å¤„ç† ---")

        # æ¨¡æ‹Ÿ4æ ¸CPU
        mock_cpu_count.return_value = 4

        aggregator = DailyDataAggregator(
            data_dir=str(self.data_dir), output_dir=str(self.output_dir)
        )
        aggregator.load_coin_data()

        # è¿™ä¸ªæµ‹è¯•ä¸»è¦éªŒè¯å¹¶å‘ä»£ç ä¸ä¼šå´©æºƒ
        # å®é™…çš„å¹¶å‘æµ‹è¯•å¾ˆéš¾åœ¨å•å…ƒæµ‹è¯•ä¸­å®Œå…¨æ¨¡æ‹Ÿ
        try:
            # åªæ„å»ºä¸€å¤©çš„æ•°æ®ï¼Œé¿å…è¿‡é•¿æµ‹è¯•æ—¶é—´
            start_date = aggregator.min_date
            end_date = aggregator.min_date

            with patch.object(aggregator, "get_daily_data") as mock_get_daily:
                mock_get_daily.return_value = pd.DataFrame()

                # è¿™ä¸ªè°ƒç”¨åº”è¯¥ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
                aggregator.build_daily_tables(force_recalculate=True)

            print("âœ… å¹¶å‘å¤„ç†ä»£ç ç»“æ„æ­£å¸¸")
        except Exception as e:
            self.fail(f"å¹¶å‘å¤„ç†æµ‹è¯•å¤±è´¥: {e}")


class TestDailyAggregatorConvenienceFunction(unittest.TestCase):
    """æµ‹è¯•ä¾¿æ·å‡½æ•°"""

    def test_build_daily_market_summary_method(self):
        """æµ‹è¯•æ¯æ—¥å¸‚åœºæ‘˜è¦æ„å»ºæ–¹æ³•"""
        print("\n--- æµ‹è¯•æ¯æ—¥å¸‚åœºæ‘˜è¦æ„å»º ---")

        with tempfile.TemporaryDirectory() as temp_dir:
            data_dir = Path(temp_dir) / "coins"
            output_dir = Path(temp_dir) / "daily"
            data_dir.mkdir(parents=True)
            output_dir.mkdir(parents=True)

            # åˆ›å»ºç®€å•æµ‹è¯•æ•°æ®
            test_data = pd.DataFrame(
                {
                    "timestamp": [pd.Timestamp("2024-01-01").timestamp() * 1000],
                    "price": [40000],
                    "volume": [1e9],
                    "market_cap": [8e11],
                }
            )

            test_file = data_dir / "bitcoin.csv"
            test_data.to_csv(test_file, index=False)

            # æµ‹è¯•æ–¹æ³•è°ƒç”¨
            try:
                aggregator = DailyDataAggregator(
                    data_dir=str(data_dir), output_dir=str(output_dir)
                )
                aggregator.load_coin_data()

                # æµ‹è¯• build_daily_market_summary æ–¹æ³•
                result = aggregator.build_daily_market_summary()

                # éªŒè¯è¿”å›äº† DataFrame
                self.assertIsInstance(result, pd.DataFrame)

                print("âœ… æ¯æ—¥å¸‚åœºæ‘˜è¦æ„å»ºæ–¹æ³•æµ‹è¯•é€šè¿‡")
            except Exception as e:
                print(f"âš ï¸ æ¯æ—¥å¸‚åœºæ‘˜è¦æµ‹è¯•è·³è¿‡ (æ­£å¸¸ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ•°æ®): {e}")
                # ä¸è®©æµ‹è¯•å¤±è´¥ï¼Œè¿™å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ•°æ®è®¾ç½®


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("å¼€å§‹è¿è¡Œ DailyDataAggregator æµ‹è¯•")
    print("=" * 60)

    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    # åŠ è½½æµ‹è¯•
    suite.addTests(loader.loadTestsFromTestCase(TestDailyDataAggregator))
    suite.addTests(loader.loadTestsFromTestCase(TestDailyAggregatorConvenienceFunction))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    print("\n" + "=" * 60)
    print(f"æµ‹è¯•å®Œæˆ: {result.testsRun} ä¸ªæµ‹è¯•è¿è¡Œ")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    print("=" * 60)

    return result.wasSuccessful()


class TestDailyDataAggregatorCacheFix(unittest.TestCase):
    """æµ‹è¯• result_include_all å‚æ•°ç¼“å­˜ä¿®å¤"""
    
    def setUp(self):
        """æµ‹è¯•å‡†å¤‡"""
        self.aggregator = DailyDataAggregator()
        self.test_date = '2023-10-01'
        
        # æµ‹è¯•ç”¨çš„ç¨³å®šå¸å’ŒåŒ…è£…å¸åˆ—è¡¨
        self.stablecoins = ['tether', 'usd-coin', 'binance-usd', 'dai']
        self.wrapped_coins = ['wrapped-bitcoin', 'weth']
    
    def test_cache_behavior_comprehensive(self):
        """å…¨é¢æµ‹è¯•ç¼“å­˜è¡Œä¸ºå’Œå‚æ•°è¿‡æ»¤"""
        print('\nğŸ§ª æµ‹è¯•ç¼“å­˜ä¿®å¤åçš„ result_include_all å‚æ•°è¡Œä¸º')
        
        # æ¸…ç©ºç¼“å­˜
        self.aggregator.daily_cache.clear()
        
        # 1. è·å–å…¨éƒ¨æ•°æ®ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
        data_all = self.aggregator.get_daily_data(
            target_date=self.test_date, 
            result_include_all=True, 
            force_refresh=True
        )
        
        # 2. ä»ç¼“å­˜è·å–åŸç”Ÿæ•°æ®
        data_native = self.aggregator.get_daily_data(
            target_date=self.test_date, 
            result_include_all=False, 
            force_refresh=False
        )
        
        # 3. éªŒè¯è¿‡æ»¤æ•ˆæœ
        self.assertGreater(len(data_all), len(data_native), 
                          "å…¨éƒ¨æ•°æ®åº”è¯¥æ¯”åŸç”Ÿæ•°æ®å¤š")
        
        # 4. éªŒè¯ç¨³å®šå¸è¢«è¿‡æ»¤
        found_stables = [s for s in self.stablecoins if s in data_native['coin_id'].values]
        self.assertEqual(len(found_stables), 0, 
                        f"åŸç”Ÿæ•°æ®ä¸­ä¸åº”åŒ…å«ç¨³å®šå¸ï¼Œä½†å‘ç°: {found_stables}")
        
        # 5. éªŒè¯åŒ…è£…å¸è¢«è¿‡æ»¤  
        found_wrapped = [w for w in self.wrapped_coins if w in data_native['coin_id'].values]
        self.assertEqual(len(found_wrapped), 0,
                        f"åŸç”Ÿæ•°æ®ä¸­ä¸åº”åŒ…å«åŒ…è£…å¸ï¼Œä½†å‘ç°: {found_wrapped}")
        
        print(f'âœ… ç¼“å­˜æµ‹è¯•é€šè¿‡: å…¨éƒ¨({len(data_all)}) vs åŸç”Ÿ({len(data_native)})')
    
    def test_file_cache_behavior(self):
        """æµ‹è¯•æ–‡ä»¶ç¼“å­˜è¡Œä¸º"""
        print('\nğŸ§ª æµ‹è¯•æ–‡ä»¶ç¼“å­˜çš„å‚æ•°è¿‡æ»¤è¡Œä¸º')
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼Œä¿ç•™æ–‡ä»¶ç¼“å­˜
        self.aggregator.daily_cache.clear()
        
        # ä»æ–‡ä»¶ç¼“å­˜è·å–åŸç”Ÿæ•°æ®
        data_native_file = self.aggregator.get_daily_data(
            target_date=self.test_date,
            result_include_all=False,
            force_refresh=False
        )
        
        # éªŒè¯æ–‡ä»¶ç¼“å­˜ä¹Ÿæ­£ç¡®è¿‡æ»¤
        found_stables = [s for s in self.stablecoins if s in data_native_file['coin_id'].values]
        self.assertEqual(len(found_stables), 0,
                        f"æ–‡ä»¶ç¼“å­˜çš„åŸç”Ÿæ•°æ®ä¸åº”åŒ…å«ç¨³å®šå¸ï¼Œä½†å‘ç°: {found_stables}")
        
        print(f'âœ… æ–‡ä»¶ç¼“å­˜æµ‹è¯•é€šè¿‡: åŸç”Ÿæ•°æ®({len(data_native_file)})æ­£ç¡®è¿‡æ»¤')


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)
